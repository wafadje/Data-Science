{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03-Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://images.unsplash.com/photo-1478796415026-3c85ee65975e?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=1050&q=80)\n",
    "Photo by [Gaelle Marcel](https://unsplash.com/photos/gIj7RJPAkJA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will implement your own forward propagation of a neural network, using Python and numpy only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We consider again our example of neural network in the lectures:\n",
    "![](../../../00-Lectures/images/MLP_with_activations.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin by defining a numpy array `X` with 3 random values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define X\n",
    "X = np.random.randint(0, 10, size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now redefine the sigmoid function, which will be our activation function in our neural network.\n",
    "\n",
    "Reminder:\n",
    "$$\n",
    "sigmoid(x) = \\frac{1}{1 + e^{- x}} \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define the sigmoid function as g(x)\n",
    "g = 1 / (1+ np.exp(-X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see on the plot, $a^{[1]}_1$ is computed with the values $x_1$, $x_2$ and $x_3$ as well as the associated weights $W^{[1]}_{1}$ and $b^{[1]}_{1}$:\n",
    "\n",
    "$$\n",
    "a^{[1]}_{1} = g(W^{[1]}_{1} \\times X + b^{[1]}_{1})\n",
    "$$\n",
    "\n",
    "Begin by defining randomly $W^{[1]}_{1}$ (which is a numpy array of three values) and $b^{[1]}_{1}$ and then compute $a^{[1]}_{1}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute the activation of the first unit of the first layer a11\n",
    "W1 = np.random.randint(0, 10, size=3)\n",
    "b1 = np.random.randint(0, 10, size=3)\n",
    "\n",
    "W2 = np.random.randint(0, 10, size=3)\n",
    "b2 = np.random.randint(0, 10, size=3)\n",
    "\n",
    "W3 = np.random.randint(0, 10, size=3)\n",
    "b3 = np.random.randint(0, 10, size=3)\n",
    "\n",
    "W4 = np.random.randint(0, 10, size=3)\n",
    "b4 = np.random.randint(0, 10, size=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for the two other units of the first layer: compute $a^{[1]}_2$, $a^{[1]}_3$ and $a^{[1]}_4$ as `a12`, `a13` and `a14`.\n",
    "\n",
    "Reminder:\n",
    "\n",
    "$$\n",
    "a^{[1]}_{2} = g(W^{[1]}_{2} \\times X + b^{[1]}_{2})\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{[1]}_{3} = g(W^{[1]}_{3} \\times X + b^{[1]}_{3})\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{[1]}_{4} = g(W^{[1]}_{4} \\times X + b^{[1]}_{4})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute a12, a13 and a14\n",
    "\n",
    "a11 = (W1 * X + b1) * g\n",
    "\n",
    "a12 = (W2 * X + b2) * g\n",
    "\n",
    "a13 = (W3 * X + b3) * g\n",
    "\n",
    "a14 = (W4 * X + b4) * g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to transform our values $a^{[1]}_i$ (saved into `a11`, `a12`, `a13` and `a14` into a single vector of 4 values `a1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.92423431, 13.96538328, 52.98222644,  5.84846863, 49.87636884,\n",
       "       24.99161625])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: compute a1\n",
    "a1 = np.concat(a11, a12)\n",
    "a1 = np.append(a13, a14)\n",
    "a1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first layer is computed, now let's continue, we want to compute the values of the second layer, using the following formulas, still defining random values for weights and bias:\n",
    "\n",
    "$$\n",
    "a^{[2]}_{1} = g( W^{[2]}_{1} \\times a^{[1]} + b^{[2]}_{1})\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{[2]}_{2} = g(W^{[2]}_{2} \\times a^{[1]} + b^{[2]}_{2})\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{[2]}_{3} = g(W^{[2]}_{3} \\times a^{[1]} + b^{[2]}_{3})\n",
    "$$\n",
    "\n",
    "$$\n",
    "a^{[2]}_{4} = g(W^{[2]}_{4} \\times a^{[1]} + b^{[2]}_{4})\n",
    "$$\n",
    "\n",
    "Be careful, now the weights $W^{[2]}_i$ might not have the same dimension..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute a21, a22, a23, a24\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, compute the vector `a2`, concatenation of `a21`, `a22`, `a23` and `a24`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute a2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, compute the output value `a3` using the following formula:\n",
    "\n",
    "$$\n",
    "a^{[3]}_{1} = g(W^{[3]}_{1} \\times a^{[2]} + b^{[3]}_{1})\n",
    "$$\n",
    "\n",
    "Again with random weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute a3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have built your own neural network, impressive, right?\n",
    "\n",
    "You now know how a neural network can compute a value (for regression or classification) just by having units and layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optional: vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part is optional and a bit more complicated.\n",
    "\n",
    "You might have noticed that we made a lot of computations that could be vectorized. Meaning, instead of computing separately `a11`, `a12`, `a13`, `a14`, we could have compute directly `a1`. It works for other layers too. We will do it that way now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep our input vector `X`, and define a weight matrix `W1` and a bias vector `b1` randomly. And then, having those three variables, compute `a1` in just one line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute a1 in one line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It gets easier, right? Now that you got it, compute `a2` and finally `a3` in just a couple of lines of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute a2 and a3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is called vectorization, and helps a lot in computing matrix calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you still have time, you can try to define a function that takes as parameters an input vector `X`, the number of layers `L` and the units per layer `units` and returns the output of the associated neural network."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
