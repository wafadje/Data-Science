{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
      "\u001b[K    100% |████████████████████████████████| 317kB 1.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 1.1MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /home/wafa/bin/anaconda/lib/python3.6/site-packages (from keras) (1.11.0)\n",
      "Collecting keras-applications>=1.0.6 (from keras)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl (51kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 1.7MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /home/wafa/bin/anaconda/lib/python3.6/site-packages (from keras) (1.15.4)\n",
      "Requirement already satisfied: h5py in /home/wafa/bin/anaconda/lib/python3.6/site-packages (from keras) (2.7.1)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/wafa/bin/anaconda/lib/python3.6/site-packages (from keras) (1.2.0)\n",
      "Requirement already satisfied: pyyaml in /home/wafa/bin/anaconda/lib/python3.6/site-packages (from keras) (3.12)\n",
      "Installing collected packages: keras-preprocessing, keras-applications, keras\n",
      "Successfully installed keras-2.2.4 keras-applications-1.0.7 keras-preprocessing-1.0.9\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n",
      "\u001b[K    100% |████████████████████████████████| 92.5MB 270kB/s ta 0:00:01    20% |██████▌                         | 18.9MB 594kB/s eta 0:02:04    32% |██████████▍                     | 30.2MB 397kB/s eta 0:02:37    55% |█████████████████▊              | 51.3MB 427kB/s eta 0:01:37\n",
      "\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/dc/5503d89e530988eb7a1aed337dcb456ef8150f7c06132233bd9e41ec0215/grpcio-1.19.0-cp36-cp36m-manylinux1_x86_64.whl (10.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.8MB 1.1MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/wafa/bin/anaconda/lib/python3.6/site-packages (from tensorflow) (0.32.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /home/wafa/bin/anaconda/lib/python3.6/site-packages (from tensorflow) (1.11.0)\n",
      "Collecting tensorboard<1.14.0,>=1.13.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/7b/3ee06856ec30d5136cd2002408df1d111fcff269f3691147dbf3b8dc0ba2/tensorboard-1.13.0-py3-none-any.whl (3.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 3.2MB 1.4MB/s ta 0:00:01    18% |██████                          | 593kB 990kB/s eta 0:00:03\n",
      "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /home/wafa/bin/anaconda/lib/python3.6/site-packages (from tensorflow) (1.0.9)\n",
      "Collecting protobuf>=3.6.1 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/60/ca38e967360212ddbb004141a70f5f6d47296e1fba37964d8ac6cb631921/protobuf-3.7.0-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.2MB 1.5MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /home/wafa/bin/anaconda/lib/python3.6/site-packages (from tensorflow) (1.0.7)\n",
      "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
      "\u001b[K    100% |████████████████████████████████| 368kB 1.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
      "Collecting gast>=0.2.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/wafa/bin/anaconda/lib/python3.6/site-packages (from tensorflow) (1.15.4)\n",
      "Collecting astor>=0.6.0 (from tensorflow)\n",
      "  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\n",
      "Collecting absl-py>=0.1.6 (from tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/bc/ab68120d1d89ae23b694a55fe2aece2f91194313b71f9b05a80b32d3c24b/absl-py-0.7.0.tar.gz (96kB)\n",
      "\u001b[K    100% |████████████████████████████████| 102kB 1.1MB/s a 0:00:011\n",
      "\u001b[?25hCollecting markdown>=2.6.8 (from tensorboard<1.14.0,>=1.13.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl (89kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 886kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: werkzeug>=0.11.15 in /home/wafa/bin/anaconda/lib/python3.6/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow) (0.14.1)\n",
      "Requirement already satisfied: setuptools in /home/wafa/bin/anaconda/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow) (40.8.0)\n",
      "Requirement already satisfied: h5py in /home/wafa/bin/anaconda/lib/python3.6/site-packages (from keras-applications>=1.0.6->tensorflow) (2.7.1)\n",
      "Collecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 639kB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pbr>=0.11 (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/09/12fe9a14237a6b7e0ba3a8d6fcf254bf4b10ec56a0185f73d651145e9222/pbr-5.1.3-py2.py3-none-any.whl (107kB)\n",
      "\u001b[K    100% |████████████████████████████████| 112kB 1.2MB/s ta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor, gast, absl-py\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/wafa/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
      "  Building wheel for gast (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/wafa/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
      "  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/wafa/.cache/pip/wheels/90/db/f8/2c3101f72ef1ad434e4662853174126ce30201a3e163dcbeca\n",
      "Successfully built termcolor gast absl-py\n",
      "Installing collected packages: grpcio, markdown, protobuf, absl-py, tensorboard, pbr, mock, tensorflow-estimator, termcolor, gast, astor, tensorflow\n",
      "Successfully installed absl-py-0.7.0 astor-0.7.1 gast-0.2.2 grpcio-1.19.0 markdown-3.0.1 mock-2.0.0 pbr-5.1.3 protobuf-3.7.0 tensorboard-1.13.0 tensorflow-1.13.1 tensorflow-estimator-1.13.0 termcolor-1.1.0\n",
      "\u001b[33mYou are using pip version 19.0.1, however version 19.0.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I.1. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and load the dataset\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston().data\n",
    "target = load_boston().target\n",
    "features = load_boston().feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Have a peek on the data\n",
    "import pandas as pd\n",
    "\n",
    "X_df = pd.DataFrame(data=data, columns=features)\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's scale basically and split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_df = (X_df -X_df.mean())/X_df.std()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_df, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Sequential object\n",
    "def model_five_layers(input_dim):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add the first Dense layers of 100 units with the input dimension\n",
    "    model.add(Dense(100, input_dim=input_dim, activation='sigmoid'))\n",
    "\n",
    "    # Add four more layers of 100 units\n",
    "    model.add(Dense(200, activation='sigmoid'))\n",
    "    model.add(Dense(200, activation='sigmoid'))\n",
    "    model.add(Dense(200, activation='sigmoid'))\n",
    "    model.add(Dense(200, activation='sigmoid'))\n",
    "\n",
    "    # Add finally the output layer with one unit: the predicted result\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/wafa/bin/anaconda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/wafa/bin/anaconda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 404 samples, validate on 102 samples\n",
      "Epoch 1/200\n",
      "404/404 [==============================] - 2s 6ms/step - loss: 182.4390 - val_loss: 82.5626\n",
      "Epoch 2/200\n",
      "404/404 [==============================] - 0s 83us/step - loss: 92.1421 - val_loss: 77.2509\n",
      "Epoch 3/200\n",
      "404/404 [==============================] - 0s 105us/step - loss: 87.6047 - val_loss: 73.8944\n",
      "Epoch 4/200\n",
      "404/404 [==============================] - 0s 78us/step - loss: 87.6403 - val_loss: 75.1521\n",
      "Epoch 5/200\n",
      "404/404 [==============================] - 0s 105us/step - loss: 89.6134 - val_loss: 73.8378\n",
      "Epoch 6/200\n",
      "404/404 [==============================] - 0s 102us/step - loss: 90.4764 - val_loss: 74.0693\n",
      "Epoch 7/200\n",
      "404/404 [==============================] - 0s 86us/step - loss: 88.4219 - val_loss: 73.3411\n",
      "Epoch 8/200\n",
      "404/404 [==============================] - 0s 114us/step - loss: 87.9043 - val_loss: 99.8751\n",
      "Epoch 9/200\n",
      "404/404 [==============================] - 0s 107us/step - loss: 95.1691 - val_loss: 76.2861\n",
      "Epoch 10/200\n",
      "404/404 [==============================] - 0s 86us/step - loss: 88.5584 - val_loss: 78.8073\n",
      "Epoch 11/200\n",
      "404/404 [==============================] - 0s 127us/step - loss: 92.4902 - val_loss: 73.3995\n",
      "Epoch 12/200\n",
      "404/404 [==============================] - 0s 107us/step - loss: 87.4863 - val_loss: 76.8031\n",
      "Epoch 13/200\n",
      "404/404 [==============================] - 0s 113us/step - loss: 88.3981 - val_loss: 78.7838\n",
      "Epoch 14/200\n",
      "404/404 [==============================] - 0s 125us/step - loss: 89.6296 - val_loss: 73.3064\n",
      "Epoch 15/200\n",
      "404/404 [==============================] - 0s 103us/step - loss: 88.3013 - val_loss: 73.3796\n",
      "Epoch 16/200\n",
      "404/404 [==============================] - 0s 125us/step - loss: 88.8118 - val_loss: 74.3889\n",
      "Epoch 17/200\n",
      "404/404 [==============================] - 0s 96us/step - loss: 91.4970 - val_loss: 89.7412\n",
      "Epoch 18/200\n",
      "404/404 [==============================] - 0s 102us/step - loss: 87.9558 - val_loss: 73.8902\n",
      "Epoch 19/200\n",
      "404/404 [==============================] - 0s 127us/step - loss: 87.9686 - val_loss: 76.5250\n",
      "Epoch 20/200\n",
      "404/404 [==============================] - 0s 116us/step - loss: 87.9398 - val_loss: 74.3891\n",
      "Epoch 21/200\n",
      "404/404 [==============================] - 0s 139us/step - loss: 87.9705 - val_loss: 77.0607\n",
      "Epoch 22/200\n",
      "404/404 [==============================] - 0s 112us/step - loss: 90.4398 - val_loss: 73.4765\n",
      "Epoch 23/200\n",
      "404/404 [==============================] - 0s 97us/step - loss: 87.7219 - val_loss: 76.2416\n",
      "Epoch 24/200\n",
      "404/404 [==============================] - 0s 132us/step - loss: 88.0280 - val_loss: 86.9111\n",
      "Epoch 25/200\n",
      "404/404 [==============================] - 0s 114us/step - loss: 89.0538 - val_loss: 89.4689\n",
      "Epoch 26/200\n",
      "404/404 [==============================] - 0s 99us/step - loss: 94.8957 - val_loss: 89.8500\n",
      "Epoch 27/200\n",
      "404/404 [==============================] - 0s 139us/step - loss: 89.6688 - val_loss: 79.7157\n",
      "Epoch 28/200\n",
      "404/404 [==============================] - 0s 120us/step - loss: 89.1392 - val_loss: 73.3650\n",
      "Epoch 29/200\n",
      "404/404 [==============================] - 0s 101us/step - loss: 88.2401 - val_loss: 87.8178\n",
      "Epoch 30/200\n",
      "404/404 [==============================] - 0s 96us/step - loss: 87.5450 - val_loss: 76.3804\n",
      "Epoch 31/200\n",
      "404/404 [==============================] - 0s 119us/step - loss: 89.1112 - val_loss: 93.5518\n",
      "Epoch 32/200\n",
      "404/404 [==============================] - 0s 130us/step - loss: 88.0584 - val_loss: 76.4124\n",
      "Epoch 33/200\n",
      "404/404 [==============================] - 0s 109us/step - loss: 86.6265 - val_loss: 73.6377\n",
      "Epoch 34/200\n",
      "404/404 [==============================] - 0s 118us/step - loss: 89.6617 - val_loss: 97.4663\n",
      "Epoch 35/200\n",
      "404/404 [==============================] - 0s 96us/step - loss: 91.8652 - val_loss: 73.8308\n",
      "Epoch 36/200\n",
      "404/404 [==============================] - 0s 106us/step - loss: 89.3582 - val_loss: 80.7555\n",
      "Epoch 37/200\n",
      "404/404 [==============================] - 0s 113us/step - loss: 89.4611 - val_loss: 73.2667\n",
      "Epoch 38/200\n",
      "404/404 [==============================] - 0s 124us/step - loss: 88.4090 - val_loss: 77.8789\n",
      "Epoch 39/200\n",
      "404/404 [==============================] - 0s 111us/step - loss: 88.6089 - val_loss: 81.6385\n",
      "Epoch 40/200\n",
      "404/404 [==============================] - 0s 88us/step - loss: 87.6758 - val_loss: 73.7387\n",
      "Epoch 41/200\n",
      "404/404 [==============================] - 0s 97us/step - loss: 87.4692 - val_loss: 80.2687\n",
      "Epoch 42/200\n",
      "404/404 [==============================] - 0s 107us/step - loss: 90.7528 - val_loss: 73.1544\n",
      "Epoch 43/200\n",
      "404/404 [==============================] - 0s 97us/step - loss: 89.3134 - val_loss: 73.6684\n",
      "Epoch 44/200\n",
      "404/404 [==============================] - 0s 97us/step - loss: 87.9938 - val_loss: 74.9653\n",
      "Epoch 45/200\n",
      "404/404 [==============================] - 0s 105us/step - loss: 87.1567 - val_loss: 73.7169\n",
      "Epoch 46/200\n",
      "404/404 [==============================] - 0s 121us/step - loss: 87.2433 - val_loss: 74.2257\n",
      "Epoch 47/200\n",
      "404/404 [==============================] - 0s 92us/step - loss: 89.9678 - val_loss: 76.6187\n",
      "Epoch 48/200\n",
      "404/404 [==============================] - 0s 110us/step - loss: 86.2543 - val_loss: 76.3279\n",
      "Epoch 49/200\n",
      "404/404 [==============================] - 0s 85us/step - loss: 88.6807 - val_loss: 74.9238\n",
      "Epoch 50/200\n",
      "404/404 [==============================] - 0s 87us/step - loss: 89.2456 - val_loss: 73.8755\n",
      "Epoch 51/200\n",
      "404/404 [==============================] - 0s 88us/step - loss: 86.6968 - val_loss: 74.3164\n",
      "Epoch 52/200\n",
      "404/404 [==============================] - 0s 83us/step - loss: 86.8432 - val_loss: 76.9203\n",
      "Epoch 53/200\n",
      "404/404 [==============================] - 0s 82us/step - loss: 87.0587 - val_loss: 73.9360\n",
      "Epoch 54/200\n",
      "404/404 [==============================] - 0s 89us/step - loss: 88.5623 - val_loss: 74.6852\n",
      "Epoch 55/200\n",
      "404/404 [==============================] - 0s 95us/step - loss: 86.8545 - val_loss: 74.1050\n",
      "Epoch 56/200\n",
      "404/404 [==============================] - 0s 86us/step - loss: 87.1586 - val_loss: 81.4452\n",
      "Epoch 57/200\n",
      "404/404 [==============================] - 0s 75us/step - loss: 84.5928 - val_loss: 74.0686\n",
      "Epoch 58/200\n",
      "404/404 [==============================] - 0s 89us/step - loss: 90.1855 - val_loss: 73.0972\n",
      "Epoch 59/200\n",
      "404/404 [==============================] - 0s 85us/step - loss: 88.6093 - val_loss: 72.6924\n",
      "Epoch 60/200\n",
      "404/404 [==============================] - 0s 85us/step - loss: 87.8696 - val_loss: 82.1160\n",
      "Epoch 61/200\n",
      "404/404 [==============================] - 0s 82us/step - loss: 86.2394 - val_loss: 85.2528\n",
      "Epoch 62/200\n",
      "404/404 [==============================] - 0s 70us/step - loss: 86.9422 - val_loss: 72.8003\n",
      "Epoch 63/200\n",
      "404/404 [==============================] - 0s 90us/step - loss: 88.3018 - val_loss: 73.8315\n",
      "Epoch 64/200\n",
      "404/404 [==============================] - 0s 87us/step - loss: 85.7656 - val_loss: 75.8291\n",
      "Epoch 65/200\n",
      "404/404 [==============================] - 0s 81us/step - loss: 85.6353 - val_loss: 72.1549\n",
      "Epoch 66/200\n",
      "404/404 [==============================] - 0s 81us/step - loss: 86.4530 - val_loss: 71.7296\n",
      "Epoch 67/200\n",
      "404/404 [==============================] - 0s 82us/step - loss: 85.1649 - val_loss: 73.2749\n",
      "Epoch 68/200\n",
      "404/404 [==============================] - 0s 81us/step - loss: 85.2663 - val_loss: 71.6030\n",
      "Epoch 69/200\n",
      "404/404 [==============================] - 0s 80us/step - loss: 84.1266 - val_loss: 87.3826\n",
      "Epoch 70/200\n",
      "404/404 [==============================] - 0s 74us/step - loss: 84.6405 - val_loss: 69.8351\n",
      "Epoch 71/200\n",
      "404/404 [==============================] - 0s 86us/step - loss: 86.4864 - val_loss: 72.5568\n",
      "Epoch 72/200\n",
      "404/404 [==============================] - 0s 68us/step - loss: 81.3505 - val_loss: 67.2725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/200\n",
      "404/404 [==============================] - 0s 78us/step - loss: 80.4269 - val_loss: 78.4958\n",
      "Epoch 74/200\n",
      "404/404 [==============================] - 0s 82us/step - loss: 76.9122 - val_loss: 81.9541\n",
      "Epoch 75/200\n",
      "404/404 [==============================] - 0s 75us/step - loss: 77.3735 - val_loss: 55.3152\n",
      "Epoch 76/200\n",
      "404/404 [==============================] - 0s 69us/step - loss: 67.6769 - val_loss: 48.6799\n",
      "Epoch 77/200\n",
      "404/404 [==============================] - 0s 80us/step - loss: 54.0761 - val_loss: 42.5269\n",
      "Epoch 78/200\n",
      "404/404 [==============================] - 0s 83us/step - loss: 52.7962 - val_loss: 75.8510\n",
      "Epoch 79/200\n",
      "404/404 [==============================] - 0s 90us/step - loss: 52.4522 - val_loss: 42.7385\n",
      "Epoch 80/200\n",
      "404/404 [==============================] - 0s 83us/step - loss: 57.0600 - val_loss: 31.3055\n",
      "Epoch 81/200\n",
      "404/404 [==============================] - 0s 85us/step - loss: 36.2461 - val_loss: 37.4552\n",
      "Epoch 82/200\n",
      "404/404 [==============================] - 0s 93us/step - loss: 36.2650 - val_loss: 28.0120\n",
      "Epoch 83/200\n",
      "404/404 [==============================] - 0s 77us/step - loss: 26.9052 - val_loss: 26.0125\n",
      "Epoch 84/200\n",
      "404/404 [==============================] - 0s 80us/step - loss: 36.2152 - val_loss: 131.6116\n",
      "Epoch 85/200\n",
      "404/404 [==============================] - 0s 96us/step - loss: 41.9978 - val_loss: 29.3337\n",
      "Epoch 86/200\n",
      "404/404 [==============================] - 0s 76us/step - loss: 29.3552 - val_loss: 25.0910\n",
      "Epoch 87/200\n",
      "404/404 [==============================] - 0s 74us/step - loss: 24.1977 - val_loss: 27.6358\n",
      "Epoch 88/200\n",
      "404/404 [==============================] - 0s 82us/step - loss: 24.1359 - val_loss: 31.8429\n",
      "Epoch 89/200\n",
      "404/404 [==============================] - 0s 76us/step - loss: 54.9468 - val_loss: 38.9440\n",
      "Epoch 90/200\n",
      "404/404 [==============================] - 0s 69us/step - loss: 27.4028 - val_loss: 36.8916\n",
      "Epoch 91/200\n",
      "404/404 [==============================] - 0s 92us/step - loss: 24.0683 - val_loss: 25.0422\n",
      "Epoch 92/200\n",
      "404/404 [==============================] - 0s 81us/step - loss: 26.3684 - val_loss: 25.5623\n",
      "Epoch 93/200\n",
      "404/404 [==============================] - 0s 80us/step - loss: 23.3673 - val_loss: 40.0727\n",
      "Epoch 94/200\n",
      "404/404 [==============================] - 0s 75us/step - loss: 27.8560 - val_loss: 32.5795\n",
      "Epoch 95/200\n",
      "404/404 [==============================] - 0s 71us/step - loss: 41.3712 - val_loss: 29.5647\n",
      "Epoch 96/200\n",
      "404/404 [==============================] - 0s 80us/step - loss: 30.3403 - val_loss: 25.5674\n",
      "Epoch 97/200\n",
      "404/404 [==============================] - 0s 73us/step - loss: 25.1163 - val_loss: 41.2030\n",
      "Epoch 98/200\n",
      "404/404 [==============================] - 0s 85us/step - loss: 25.7413 - val_loss: 34.7323\n",
      "Epoch 99/200\n",
      "404/404 [==============================] - 0s 88us/step - loss: 28.1048 - val_loss: 53.3528\n",
      "Epoch 100/200\n",
      "404/404 [==============================] - 0s 82us/step - loss: 30.5555 - val_loss: 27.3869\n",
      "Epoch 101/200\n",
      "404/404 [==============================] - 0s 82us/step - loss: 26.9998 - val_loss: 22.8762\n",
      "Epoch 102/200\n",
      "404/404 [==============================] - 0s 82us/step - loss: 23.7142 - val_loss: 33.6678\n",
      "Epoch 103/200\n",
      "404/404 [==============================] - 0s 77us/step - loss: 29.2041 - val_loss: 22.5916\n",
      "Epoch 104/200\n",
      "404/404 [==============================] - 0s 79us/step - loss: 21.6298 - val_loss: 22.0176\n",
      "Epoch 105/200\n",
      "404/404 [==============================] - 0s 69us/step - loss: 22.9482 - val_loss: 38.5216\n",
      "Epoch 106/200\n",
      "404/404 [==============================] - 0s 81us/step - loss: 31.8699 - val_loss: 22.9034\n",
      "Epoch 107/200\n",
      "404/404 [==============================] - 0s 79us/step - loss: 23.3532 - val_loss: 23.0361\n",
      "Epoch 108/200\n",
      "404/404 [==============================] - 0s 100us/step - loss: 21.1614 - val_loss: 22.3799\n",
      "Epoch 109/200\n",
      "404/404 [==============================] - 0s 77us/step - loss: 22.7595 - val_loss: 33.8013\n",
      "Epoch 110/200\n",
      "404/404 [==============================] - 0s 77us/step - loss: 28.9992 - val_loss: 36.0423\n",
      "Epoch 111/200\n",
      "404/404 [==============================] - 0s 80us/step - loss: 27.2790 - val_loss: 21.7464\n",
      "Epoch 112/200\n",
      "404/404 [==============================] - 0s 84us/step - loss: 20.9723 - val_loss: 69.2946\n",
      "Epoch 113/200\n",
      "404/404 [==============================] - 0s 71us/step - loss: 48.0013 - val_loss: 37.6689\n",
      "Epoch 114/200\n",
      "404/404 [==============================] - 0s 82us/step - loss: 23.2988 - val_loss: 26.4542\n",
      "Epoch 115/200\n",
      "404/404 [==============================] - 0s 83us/step - loss: 25.9503 - val_loss: 29.1003\n",
      "Epoch 116/200\n",
      "404/404 [==============================] - 0s 76us/step - loss: 21.3665 - val_loss: 23.8456\n",
      "Epoch 117/200\n",
      "404/404 [==============================] - 0s 72us/step - loss: 21.1372 - val_loss: 31.6474\n",
      "Epoch 118/200\n",
      "404/404 [==============================] - 0s 80us/step - loss: 20.6908 - val_loss: 19.7210\n",
      "Epoch 119/200\n",
      "404/404 [==============================] - 0s 76us/step - loss: 21.1924 - val_loss: 45.2129\n",
      "Epoch 120/200\n",
      "404/404 [==============================] - 0s 80us/step - loss: 25.9421 - val_loss: 23.2927\n",
      "Epoch 121/200\n",
      "404/404 [==============================] - 0s 87us/step - loss: 24.1066 - val_loss: 42.5143\n",
      "Epoch 122/200\n",
      "404/404 [==============================] - 0s 74us/step - loss: 24.7639 - val_loss: 19.1250\n",
      "Epoch 123/200\n",
      "404/404 [==============================] - 0s 87us/step - loss: 18.5395 - val_loss: 22.1718\n",
      "Epoch 124/200\n",
      "404/404 [==============================] - 0s 75us/step - loss: 19.3827 - val_loss: 19.3308\n",
      "Epoch 125/200\n",
      "404/404 [==============================] - 0s 85us/step - loss: 18.3181 - val_loss: 18.5242\n",
      "Epoch 126/200\n",
      "404/404 [==============================] - 0s 72us/step - loss: 18.8127 - val_loss: 18.6066\n",
      "Epoch 127/200\n",
      "404/404 [==============================] - 0s 82us/step - loss: 18.0915 - val_loss: 18.6497\n",
      "Epoch 128/200\n",
      "404/404 [==============================] - 0s 82us/step - loss: 21.5416 - val_loss: 29.2083\n",
      "Epoch 129/200\n",
      "404/404 [==============================] - 0s 88us/step - loss: 20.7020 - val_loss: 19.5087\n",
      "Epoch 130/200\n",
      "404/404 [==============================] - 0s 80us/step - loss: 22.8339 - val_loss: 30.3239\n",
      "Epoch 131/200\n",
      "404/404 [==============================] - 0s 84us/step - loss: 20.7475 - val_loss: 21.8850\n",
      "Epoch 132/200\n",
      "404/404 [==============================] - 0s 74us/step - loss: 17.9698 - val_loss: 18.5641\n",
      "Epoch 133/200\n",
      "404/404 [==============================] - 0s 81us/step - loss: 18.2849 - val_loss: 18.7587\n",
      "Epoch 134/200\n",
      "404/404 [==============================] - 0s 82us/step - loss: 21.3941 - val_loss: 23.3092\n",
      "Epoch 135/200\n",
      "404/404 [==============================] - 0s 75us/step - loss: 19.9263 - val_loss: 17.8137\n",
      "Epoch 136/200\n",
      "404/404 [==============================] - 0s 81us/step - loss: 17.9785 - val_loss: 20.0640\n",
      "Epoch 137/200\n",
      "404/404 [==============================] - 0s 69us/step - loss: 18.3747 - val_loss: 24.9299\n",
      "Epoch 138/200\n",
      "404/404 [==============================] - 0s 84us/step - loss: 19.7753 - val_loss: 17.7545\n",
      "Epoch 139/200\n",
      "404/404 [==============================] - 0s 79us/step - loss: 21.9855 - val_loss: 30.4514\n",
      "Epoch 140/200\n",
      "404/404 [==============================] - 0s 89us/step - loss: 18.5506 - val_loss: 16.6858\n",
      "Epoch 141/200\n",
      "404/404 [==============================] - 0s 72us/step - loss: 16.5436 - val_loss: 16.1664\n",
      "Epoch 142/200\n",
      "404/404 [==============================] - 0s 72us/step - loss: 18.4623 - val_loss: 17.0106\n",
      "Epoch 143/200\n",
      "404/404 [==============================] - 0s 85us/step - loss: 16.0872 - val_loss: 16.0130\n",
      "Epoch 144/200\n",
      "404/404 [==============================] - 0s 84us/step - loss: 15.3461 - val_loss: 16.0858\n",
      "Epoch 145/200\n",
      "404/404 [==============================] - 0s 82us/step - loss: 17.0165 - val_loss: 16.5810\n",
      "Epoch 146/200\n",
      "404/404 [==============================] - 0s 88us/step - loss: 15.5422 - val_loss: 17.0593\n",
      "Epoch 147/200\n",
      "404/404 [==============================] - 0s 78us/step - loss: 15.8749 - val_loss: 17.5884\n",
      "Epoch 148/200\n",
      "404/404 [==============================] - 0s 82us/step - loss: 16.1391 - val_loss: 17.0167\n",
      "Epoch 149/200\n",
      "404/404 [==============================] - 0s 81us/step - loss: 16.3775 - val_loss: 20.6374\n",
      "Epoch 150/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 73us/step - loss: 18.3384 - val_loss: 15.6203\n",
      "Epoch 151/200\n",
      "404/404 [==============================] - 0s 74us/step - loss: 15.4506 - val_loss: 15.3168\n",
      "Epoch 152/200\n",
      "404/404 [==============================] - 0s 78us/step - loss: 14.8268 - val_loss: 16.2680\n",
      "Epoch 153/200\n",
      "404/404 [==============================] - 0s 91us/step - loss: 15.1337 - val_loss: 15.1338\n",
      "Epoch 154/200\n",
      "404/404 [==============================] - 0s 80us/step - loss: 14.8077 - val_loss: 14.8821\n",
      "Epoch 155/200\n",
      "404/404 [==============================] - 0s 77us/step - loss: 15.1301 - val_loss: 22.9142\n",
      "Epoch 156/200\n",
      "404/404 [==============================] - 0s 74us/step - loss: 16.9011 - val_loss: 18.5252\n",
      "Epoch 157/200\n",
      "404/404 [==============================] - 0s 69us/step - loss: 15.0692 - val_loss: 14.8011\n",
      "Epoch 158/200\n",
      "404/404 [==============================] - 0s 85us/step - loss: 20.4937 - val_loss: 15.5998\n",
      "Epoch 159/200\n",
      "404/404 [==============================] - 0s 91us/step - loss: 18.1320 - val_loss: 17.5505\n",
      "Epoch 160/200\n",
      "404/404 [==============================] - 0s 74us/step - loss: 15.6012 - val_loss: 15.6505\n",
      "Epoch 161/200\n",
      "404/404 [==============================] - 0s 77us/step - loss: 16.8199 - val_loss: 16.3106\n",
      "Epoch 162/200\n",
      "404/404 [==============================] - 0s 78us/step - loss: 15.5451 - val_loss: 15.1324\n",
      "Epoch 163/200\n",
      "404/404 [==============================] - 0s 77us/step - loss: 15.2462 - val_loss: 15.7637\n",
      "Epoch 164/200\n",
      "404/404 [==============================] - 0s 82us/step - loss: 15.4668 - val_loss: 16.0596\n",
      "Epoch 165/200\n",
      "404/404 [==============================] - 0s 91us/step - loss: 15.9136 - val_loss: 15.6944\n",
      "Epoch 166/200\n",
      "404/404 [==============================] - 0s 75us/step - loss: 14.5220 - val_loss: 14.5698\n",
      "Epoch 167/200\n",
      "404/404 [==============================] - 0s 76us/step - loss: 15.0240 - val_loss: 33.3706\n",
      "Epoch 168/200\n",
      "404/404 [==============================] - 0s 78us/step - loss: 22.7482 - val_loss: 15.3068\n",
      "Epoch 169/200\n",
      "404/404 [==============================] - 0s 74us/step - loss: 15.9436 - val_loss: 14.7167\n",
      "Epoch 170/200\n",
      "404/404 [==============================] - 0s 78us/step - loss: 15.0430 - val_loss: 14.4505\n",
      "Epoch 171/200\n",
      "404/404 [==============================] - 0s 83us/step - loss: 15.5612 - val_loss: 19.0110\n",
      "Epoch 172/200\n",
      "404/404 [==============================] - 0s 74us/step - loss: 16.1940 - val_loss: 14.1725\n",
      "Epoch 173/200\n",
      "404/404 [==============================] - 0s 76us/step - loss: 14.1323 - val_loss: 15.9260\n",
      "Epoch 174/200\n",
      "404/404 [==============================] - 0s 68us/step - loss: 14.3704 - val_loss: 14.3298\n",
      "Epoch 175/200\n",
      "404/404 [==============================] - 0s 76us/step - loss: 14.7298 - val_loss: 15.1662\n",
      "Epoch 176/200\n",
      "404/404 [==============================] - 0s 62us/step - loss: 14.4200 - val_loss: 14.3071\n",
      "Epoch 177/200\n",
      "404/404 [==============================] - 0s 80us/step - loss: 14.6249 - val_loss: 18.9491\n",
      "Epoch 178/200\n",
      "404/404 [==============================] - 0s 71us/step - loss: 14.9898 - val_loss: 17.0950\n",
      "Epoch 179/200\n",
      "404/404 [==============================] - 0s 68us/step - loss: 15.2554 - val_loss: 14.2609\n",
      "Epoch 180/200\n",
      "404/404 [==============================] - 0s 73us/step - loss: 13.6821 - val_loss: 13.7021\n",
      "Epoch 181/200\n",
      "404/404 [==============================] - 0s 83us/step - loss: 13.6357 - val_loss: 13.9019\n",
      "Epoch 182/200\n",
      "404/404 [==============================] - 0s 87us/step - loss: 13.9202 - val_loss: 16.8911\n",
      "Epoch 183/200\n",
      "404/404 [==============================] - 0s 84us/step - loss: 14.7748 - val_loss: 16.5417\n",
      "Epoch 184/200\n",
      "404/404 [==============================] - 0s 73us/step - loss: 16.1911 - val_loss: 13.7525\n",
      "Epoch 185/200\n",
      "404/404 [==============================] - 0s 71us/step - loss: 14.2983 - val_loss: 23.4139\n",
      "Epoch 186/200\n",
      "404/404 [==============================] - 0s 80us/step - loss: 17.7635 - val_loss: 13.5885\n",
      "Epoch 187/200\n",
      "404/404 [==============================] - 0s 84us/step - loss: 13.5690 - val_loss: 15.0626\n",
      "Epoch 188/200\n",
      "404/404 [==============================] - 0s 75us/step - loss: 13.7289 - val_loss: 13.9699\n",
      "Epoch 189/200\n",
      "404/404 [==============================] - 0s 91us/step - loss: 13.9472 - val_loss: 13.6727\n",
      "Epoch 190/200\n",
      "404/404 [==============================] - 0s 88us/step - loss: 14.6867 - val_loss: 13.6002\n",
      "Epoch 191/200\n",
      "404/404 [==============================] - 0s 76us/step - loss: 16.6647 - val_loss: 17.8775\n",
      "Epoch 192/200\n",
      "404/404 [==============================] - 0s 86us/step - loss: 17.2801 - val_loss: 13.8764\n",
      "Epoch 193/200\n",
      "404/404 [==============================] - 0s 87us/step - loss: 13.4990 - val_loss: 13.9605\n",
      "Epoch 194/200\n",
      "404/404 [==============================] - 0s 79us/step - loss: 13.9294 - val_loss: 15.0770\n",
      "Epoch 195/200\n",
      "404/404 [==============================] - 0s 74us/step - loss: 14.2900 - val_loss: 14.9404\n",
      "Epoch 196/200\n",
      "404/404 [==============================] - 0s 64us/step - loss: 14.4593 - val_loss: 19.5379\n",
      "Epoch 197/200\n",
      "404/404 [==============================] - 0s 63us/step - loss: 19.2306 - val_loss: 14.2629\n",
      "Epoch 198/200\n",
      "404/404 [==============================] - 0s 74us/step - loss: 13.9589 - val_loss: 13.7310\n",
      "Epoch 199/200\n",
      "404/404 [==============================] - 0s 79us/step - loss: 13.2485 - val_loss: 15.3749\n",
      "Epoch 200/200\n",
      "404/404 [==============================] - 0s 76us/step - loss: 14.2878 - val_loss: 13.6805\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f05e4291588>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_five_layers(input_dim=X_train.shape[1])\n",
    "\n",
    "# Compile the model with mean squared error (for regression)\n",
    "model.compile(optimizer='SGD', loss='mean_squared_error')\n",
    "\n",
    "# Now fit the model on 500 epoches with a batch size of 64\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_five_layers(input_dim):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add the first Dense layers of 100 units with the input dimension\n",
    "    model.add(Dense(10, input_dim=input_dim, activation='sigmoid'))\n",
    "\n",
    "    # Add four more layers of 100 units\n",
    "    model.add(Dense(100, activation='sigmoid'))\n",
    "    model.add(Dense(100, activation='sigmoid'))\n",
    "    model.add(Dense(100, activation='sigmoid'))\n",
    "    model.add(Dense(100, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    # Add finally the output layer with one unit: the predicted result\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 102 samples\n",
      "Epoch 1/800\n",
      "404/404 [==============================] - 1s 3ms/step - loss: 183.8083 - val_loss: 73.3525\n",
      "Epoch 2/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 87.2366 - val_loss: 75.9201\n",
      "Epoch 3/800\n",
      "404/404 [==============================] - 0s 118us/step - loss: 88.4173 - val_loss: 73.4219\n",
      "Epoch 4/800\n",
      "404/404 [==============================] - 0s 119us/step - loss: 89.5395 - val_loss: 76.3244\n",
      "Epoch 5/800\n",
      "404/404 [==============================] - 0s 118us/step - loss: 87.1112 - val_loss: 73.5785\n",
      "Epoch 6/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 90.2230 - val_loss: 75.2113\n",
      "Epoch 7/800\n",
      "404/404 [==============================] - 0s 107us/step - loss: 86.3306 - val_loss: 77.9622\n",
      "Epoch 8/800\n",
      "404/404 [==============================] - 0s 122us/step - loss: 87.3467 - val_loss: 77.9491\n",
      "Epoch 9/800\n",
      "404/404 [==============================] - 0s 107us/step - loss: 87.1790 - val_loss: 76.5453\n",
      "Epoch 10/800\n",
      "404/404 [==============================] - 0s 105us/step - loss: 87.1145 - val_loss: 75.0007\n",
      "Epoch 11/800\n",
      "404/404 [==============================] - 0s 115us/step - loss: 88.1107 - val_loss: 81.3228\n",
      "Epoch 12/800\n",
      "404/404 [==============================] - 0s 112us/step - loss: 87.1250 - val_loss: 73.9822\n",
      "Epoch 13/800\n",
      "404/404 [==============================] - 0s 128us/step - loss: 88.8865 - val_loss: 82.4414\n",
      "Epoch 14/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 90.4434 - val_loss: 85.3905\n",
      "Epoch 15/800\n",
      "404/404 [==============================] - 0s 125us/step - loss: 88.7658 - val_loss: 73.9220\n",
      "Epoch 16/800\n",
      "404/404 [==============================] - 0s 112us/step - loss: 87.3762 - val_loss: 75.6579\n",
      "Epoch 17/800\n",
      "404/404 [==============================] - 0s 105us/step - loss: 88.6807 - val_loss: 94.9302\n",
      "Epoch 18/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 90.1129 - val_loss: 79.6665\n",
      "Epoch 19/800\n",
      "404/404 [==============================] - 0s 118us/step - loss: 88.6567 - val_loss: 74.0207\n",
      "Epoch 20/800\n",
      "404/404 [==============================] - 0s 115us/step - loss: 88.1002 - val_loss: 75.9363\n",
      "Epoch 21/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 87.8736 - val_loss: 83.6635\n",
      "Epoch 22/800\n",
      "404/404 [==============================] - 0s 112us/step - loss: 89.2630 - val_loss: 83.5921\n",
      "Epoch 23/800\n",
      "404/404 [==============================] - 0s 112us/step - loss: 87.9131 - val_loss: 83.6495\n",
      "Epoch 24/800\n",
      "404/404 [==============================] - 0s 119us/step - loss: 86.5244 - val_loss: 75.8400\n",
      "Epoch 25/800\n",
      "404/404 [==============================] - 0s 123us/step - loss: 87.6235 - val_loss: 81.0991\n",
      "Epoch 26/800\n",
      "404/404 [==============================] - 0s 98us/step - loss: 88.1665 - val_loss: 73.4161\n",
      "Epoch 27/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 89.7640 - val_loss: 73.3514\n",
      "Epoch 28/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 88.3897 - val_loss: 75.9398\n",
      "Epoch 29/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 87.3956 - val_loss: 73.3045\n",
      "Epoch 30/800\n",
      "404/404 [==============================] - 0s 121us/step - loss: 87.3700 - val_loss: 74.2852\n",
      "Epoch 31/800\n",
      "404/404 [==============================] - 0s 114us/step - loss: 90.4581 - val_loss: 73.5068\n",
      "Epoch 32/800\n",
      "404/404 [==============================] - 0s 117us/step - loss: 86.9964 - val_loss: 74.3076\n",
      "Epoch 33/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 87.9081 - val_loss: 79.2102\n",
      "Epoch 34/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 87.9112 - val_loss: 73.5541\n",
      "Epoch 35/800\n",
      "404/404 [==============================] - 0s 121us/step - loss: 87.7830 - val_loss: 82.9060\n",
      "Epoch 36/800\n",
      "404/404 [==============================] - 0s 119us/step - loss: 88.4075 - val_loss: 74.6104\n",
      "Epoch 37/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 86.9156 - val_loss: 80.6717\n",
      "Epoch 38/800\n",
      "404/404 [==============================] - 0s 122us/step - loss: 90.3535 - val_loss: 86.3656\n",
      "Epoch 39/800\n",
      "404/404 [==============================] - 0s 127us/step - loss: 86.5202 - val_loss: 73.2953\n",
      "Epoch 40/800\n",
      "404/404 [==============================] - 0s 118us/step - loss: 87.6516 - val_loss: 89.4021\n",
      "Epoch 41/800\n",
      "404/404 [==============================] - 0s 141us/step - loss: 89.0875 - val_loss: 75.8996\n",
      "Epoch 42/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 86.6822 - val_loss: 80.4097\n",
      "Epoch 43/800\n",
      "404/404 [==============================] - 0s 121us/step - loss: 87.1535 - val_loss: 74.6388\n",
      "Epoch 44/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 87.4312 - val_loss: 81.9240\n",
      "Epoch 45/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 87.0105 - val_loss: 73.4279\n",
      "Epoch 46/800\n",
      "404/404 [==============================] - 0s 121us/step - loss: 89.8714 - val_loss: 87.4348\n",
      "Epoch 47/800\n",
      "404/404 [==============================] - 0s 95us/step - loss: 88.0093 - val_loss: 73.3237\n",
      "Epoch 48/800\n",
      "404/404 [==============================] - 0s 110us/step - loss: 87.6905 - val_loss: 73.6907\n",
      "Epoch 49/800\n",
      "404/404 [==============================] - 0s 105us/step - loss: 87.7270 - val_loss: 74.6320\n",
      "Epoch 50/800\n",
      "404/404 [==============================] - 0s 113us/step - loss: 89.0492 - val_loss: 79.2298\n",
      "Epoch 51/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 88.0458 - val_loss: 73.8905\n",
      "Epoch 52/800\n",
      "404/404 [==============================] - 0s 114us/step - loss: 87.2901 - val_loss: 75.8954\n",
      "Epoch 53/800\n",
      "404/404 [==============================] - 0s 109us/step - loss: 87.2812 - val_loss: 93.6080\n",
      "Epoch 54/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 89.1766 - val_loss: 73.7422\n",
      "Epoch 55/800\n",
      "404/404 [==============================] - 0s 113us/step - loss: 87.7869 - val_loss: 73.3231\n",
      "Epoch 56/800\n",
      "404/404 [==============================] - 0s 80us/step - loss: 86.9058 - val_loss: 73.8476\n",
      "Epoch 57/800\n",
      "404/404 [==============================] - 0s 108us/step - loss: 86.8502 - val_loss: 73.7272\n",
      "Epoch 58/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 87.7646 - val_loss: 75.7805\n",
      "Epoch 59/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 89.1490 - val_loss: 80.6899\n",
      "Epoch 60/800\n",
      "404/404 [==============================] - 0s 98us/step - loss: 87.7468 - val_loss: 87.8206\n",
      "Epoch 61/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 87.8103 - val_loss: 73.2003\n",
      "Epoch 62/800\n",
      "404/404 [==============================] - 0s 105us/step - loss: 87.4255 - val_loss: 76.8596\n",
      "Epoch 63/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 89.5785 - val_loss: 73.3228\n",
      "Epoch 64/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 87.0912 - val_loss: 82.3096\n",
      "Epoch 65/800\n",
      "404/404 [==============================] - 0s 101us/step - loss: 91.3060 - val_loss: 73.3736\n",
      "Epoch 66/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 88.9238 - val_loss: 76.1685\n",
      "Epoch 67/800\n",
      "404/404 [==============================] - 0s 115us/step - loss: 87.1667 - val_loss: 77.9395\n",
      "Epoch 68/800\n",
      "404/404 [==============================] - 0s 99us/step - loss: 89.4562 - val_loss: 87.7483\n",
      "Epoch 69/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 87.0039 - val_loss: 94.4669\n",
      "Epoch 70/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 91.4522 - val_loss: 75.8098\n",
      "Epoch 71/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 88.0822 - val_loss: 74.1701\n",
      "Epoch 72/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 86.7751 - val_loss: 77.0285\n",
      "Epoch 73/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 91.2078 - val_loss: 80.0232\n",
      "Epoch 74/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 87.0177 - val_loss: 80.3995\n",
      "Epoch 75/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 86.6035 - val_loss: 73.5056\n",
      "Epoch 76/800\n",
      "404/404 [==============================] - 0s 116us/step - loss: 87.2383 - val_loss: 74.9195\n",
      "Epoch 77/800\n",
      "404/404 [==============================] - 0s 109us/step - loss: 87.2756 - val_loss: 79.9227\n",
      "Epoch 78/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 98us/step - loss: 87.5700 - val_loss: 74.3945\n",
      "Epoch 79/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 88.6861 - val_loss: 99.7290\n",
      "Epoch 80/800\n",
      "404/404 [==============================] - 0s 77us/step - loss: 89.1033 - val_loss: 83.0413\n",
      "Epoch 81/800\n",
      "404/404 [==============================] - 0s 98us/step - loss: 89.8733 - val_loss: 97.6599\n",
      "Epoch 82/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 93.2910 - val_loss: 73.6472\n",
      "Epoch 83/800\n",
      "404/404 [==============================] - 0s 126us/step - loss: 88.1767 - val_loss: 82.0200\n",
      "Epoch 84/800\n",
      "404/404 [==============================] - 0s 122us/step - loss: 88.7476 - val_loss: 80.5970\n",
      "Epoch 85/800\n",
      "404/404 [==============================] - 0s 109us/step - loss: 86.9389 - val_loss: 73.2619\n",
      "Epoch 86/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 88.4089 - val_loss: 73.8116\n",
      "Epoch 87/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 89.6142 - val_loss: 73.7970\n",
      "Epoch 88/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 87.1432 - val_loss: 74.2222\n",
      "Epoch 89/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 86.8491 - val_loss: 74.1236\n",
      "Epoch 90/800\n",
      "404/404 [==============================] - 0s 108us/step - loss: 87.9458 - val_loss: 89.1518\n",
      "Epoch 91/800\n",
      "404/404 [==============================] - 0s 129us/step - loss: 88.9398 - val_loss: 74.2379\n",
      "Epoch 92/800\n",
      "404/404 [==============================] - 0s 121us/step - loss: 87.2697 - val_loss: 76.5995\n",
      "Epoch 93/800\n",
      "404/404 [==============================] - 0s 122us/step - loss: 88.2065 - val_loss: 93.5693\n",
      "Epoch 94/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 88.1400 - val_loss: 80.0416\n",
      "Epoch 95/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 86.8052 - val_loss: 110.4736\n",
      "Epoch 96/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 89.4876 - val_loss: 74.9409\n",
      "Epoch 97/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 86.6909 - val_loss: 72.1002\n",
      "Epoch 98/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 87.3148 - val_loss: 88.7334\n",
      "Epoch 99/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 86.4576 - val_loss: 72.8423\n",
      "Epoch 100/800\n",
      "404/404 [==============================] - 0s 99us/step - loss: 86.8187 - val_loss: 82.2173\n",
      "Epoch 101/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 86.0343 - val_loss: 74.2469\n",
      "Epoch 102/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 84.0085 - val_loss: 80.6429\n",
      "Epoch 103/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 85.0141 - val_loss: 73.2276\n",
      "Epoch 104/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 82.8018 - val_loss: 80.5699\n",
      "Epoch 105/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 84.1806 - val_loss: 68.3490\n",
      "Epoch 106/800\n",
      "404/404 [==============================] - 0s 110us/step - loss: 81.3339 - val_loss: 66.8740\n",
      "Epoch 107/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 79.1900 - val_loss: 70.8947\n",
      "Epoch 108/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 75.8371 - val_loss: 61.3041\n",
      "Epoch 109/800\n",
      "404/404 [==============================] - 0s 107us/step - loss: 70.4639 - val_loss: 56.7697\n",
      "Epoch 110/800\n",
      "404/404 [==============================] - 0s 95us/step - loss: 65.8869 - val_loss: 51.4685\n",
      "Epoch 111/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 56.5562 - val_loss: 58.8932\n",
      "Epoch 112/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 56.6705 - val_loss: 154.8332\n",
      "Epoch 113/800\n",
      "404/404 [==============================] - 0s 75us/step - loss: 73.4666 - val_loss: 36.6532\n",
      "Epoch 114/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 38.8415 - val_loss: 32.3716\n",
      "Epoch 115/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 39.1245 - val_loss: 49.0990\n",
      "Epoch 116/800\n",
      "404/404 [==============================] - 0s 76us/step - loss: 49.6759 - val_loss: 61.4907\n",
      "Epoch 117/800\n",
      "404/404 [==============================] - 0s 74us/step - loss: 41.6353 - val_loss: 28.6239\n",
      "Epoch 118/800\n",
      "404/404 [==============================] - 0s 80us/step - loss: 30.5175 - val_loss: 29.7585\n",
      "Epoch 119/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 27.1742 - val_loss: 26.8506\n",
      "Epoch 120/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 37.0620 - val_loss: 31.6622\n",
      "Epoch 121/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 28.4724 - val_loss: 25.6489\n",
      "Epoch 122/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 34.7567 - val_loss: 52.9564\n",
      "Epoch 123/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 37.7381 - val_loss: 26.8765\n",
      "Epoch 124/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 28.7553 - val_loss: 53.7266\n",
      "Epoch 125/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 36.9627 - val_loss: 25.8058\n",
      "Epoch 126/800\n",
      "404/404 [==============================] - 0s 98us/step - loss: 27.2614 - val_loss: 40.6161\n",
      "Epoch 127/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 31.3532 - val_loss: 24.9295\n",
      "Epoch 128/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 31.4078 - val_loss: 38.3605\n",
      "Epoch 129/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 32.9937 - val_loss: 26.3290\n",
      "Epoch 130/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 24.3256 - val_loss: 25.1876\n",
      "Epoch 131/800\n",
      "404/404 [==============================] - 0s 167us/step - loss: 28.5929 - val_loss: 38.7578\n",
      "Epoch 132/800\n",
      "404/404 [==============================] - 0s 144us/step - loss: 35.0080 - val_loss: 31.3122\n",
      "Epoch 133/800\n",
      "404/404 [==============================] - 0s 139us/step - loss: 32.2479 - val_loss: 25.4841\n",
      "Epoch 134/800\n",
      "404/404 [==============================] - 0s 125us/step - loss: 28.5504 - val_loss: 23.1958\n",
      "Epoch 135/800\n",
      "404/404 [==============================] - 0s 124us/step - loss: 22.0422 - val_loss: 22.5084\n",
      "Epoch 136/800\n",
      "404/404 [==============================] - 0s 141us/step - loss: 22.7395 - val_loss: 22.2906\n",
      "Epoch 137/800\n",
      "404/404 [==============================] - 0s 192us/step - loss: 21.7760 - val_loss: 25.0111\n",
      "Epoch 138/800\n",
      "404/404 [==============================] - 0s 140us/step - loss: 27.6537 - val_loss: 44.9763\n",
      "Epoch 139/800\n",
      "404/404 [==============================] - 0s 114us/step - loss: 25.3713 - val_loss: 31.8766\n",
      "Epoch 140/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 22.2323 - val_loss: 23.8230\n",
      "Epoch 141/800\n",
      "404/404 [==============================] - 0s 128us/step - loss: 30.7720 - val_loss: 21.3958\n",
      "Epoch 142/800\n",
      "404/404 [==============================] - 0s 104us/step - loss: 24.5828 - val_loss: 28.7955\n",
      "Epoch 143/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 30.1151 - val_loss: 44.2654\n",
      "Epoch 144/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 28.8504 - val_loss: 24.9978\n",
      "Epoch 145/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 30.6977 - val_loss: 22.5091\n",
      "Epoch 146/800\n",
      "404/404 [==============================] - 0s 122us/step - loss: 24.7847 - val_loss: 21.3621\n",
      "Epoch 147/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 19.7437 - val_loss: 22.4629\n",
      "Epoch 148/800\n",
      "404/404 [==============================] - 0s 131us/step - loss: 20.1934 - val_loss: 26.8950\n",
      "Epoch 149/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 34.5888 - val_loss: 20.8510\n",
      "Epoch 150/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 19.7583 - val_loss: 20.0439\n",
      "Epoch 151/800\n",
      "404/404 [==============================] - 0s 119us/step - loss: 21.9566 - val_loss: 19.8661\n",
      "Epoch 152/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 25.3647 - val_loss: 19.7803\n",
      "Epoch 153/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 20.6091 - val_loss: 48.5869\n",
      "Epoch 154/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 30.0409 - val_loss: 19.6973\n",
      "Epoch 155/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 97us/step - loss: 23.0728 - val_loss: 32.9872\n",
      "Epoch 156/800\n",
      "404/404 [==============================] - 0s 105us/step - loss: 27.7951 - val_loss: 18.8558\n",
      "Epoch 157/800\n",
      "404/404 [==============================] - 0s 104us/step - loss: 19.0360 - val_loss: 23.6015\n",
      "Epoch 158/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 33.4042 - val_loss: 25.0980\n",
      "Epoch 159/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 20.1722 - val_loss: 18.3033\n",
      "Epoch 160/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 18.4576 - val_loss: 39.0575\n",
      "Epoch 161/800\n",
      "404/404 [==============================] - 0s 75us/step - loss: 26.7267 - val_loss: 18.0225\n",
      "Epoch 162/800\n",
      "404/404 [==============================] - 0s 95us/step - loss: 16.7427 - val_loss: 19.9193\n",
      "Epoch 163/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 25.4495 - val_loss: 17.5295\n",
      "Epoch 164/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 16.4074 - val_loss: 25.6677\n",
      "Epoch 165/800\n",
      "404/404 [==============================] - 0s 95us/step - loss: 24.2913 - val_loss: 40.4400\n",
      "Epoch 166/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 23.5162 - val_loss: 17.8451\n",
      "Epoch 167/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 16.7247 - val_loss: 18.6452\n",
      "Epoch 168/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 18.3349 - val_loss: 17.1293\n",
      "Epoch 169/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 16.5053 - val_loss: 23.0561\n",
      "Epoch 170/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 21.4829 - val_loss: 16.5968\n",
      "Epoch 171/800\n",
      "404/404 [==============================] - 0s 108us/step - loss: 16.4101 - val_loss: 34.5221\n",
      "Epoch 172/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 22.1224 - val_loss: 16.3709\n",
      "Epoch 173/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 17.9666 - val_loss: 18.2922\n",
      "Epoch 174/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 15.7630 - val_loss: 17.5305\n",
      "Epoch 175/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 18.5772 - val_loss: 16.1671\n",
      "Epoch 176/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 14.9260 - val_loss: 25.1675\n",
      "Epoch 177/800\n",
      "404/404 [==============================] - 0s 78us/step - loss: 25.0158 - val_loss: 22.4451\n",
      "Epoch 178/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 22.6349 - val_loss: 18.0684\n",
      "Epoch 179/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 14.9902 - val_loss: 19.3616\n",
      "Epoch 180/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 21.5088 - val_loss: 18.7036\n",
      "Epoch 181/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 27.5673 - val_loss: 35.4832\n",
      "Epoch 182/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 21.5753 - val_loss: 15.3748\n",
      "Epoch 183/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 14.8669 - val_loss: 18.7596\n",
      "Epoch 184/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 14.8676 - val_loss: 18.7096\n",
      "Epoch 185/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 14.1837 - val_loss: 16.5337\n",
      "Epoch 186/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 18.2805 - val_loss: 14.7105\n",
      "Epoch 187/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 15.7851 - val_loss: 17.8310\n",
      "Epoch 188/800\n",
      "404/404 [==============================] - 0s 78us/step - loss: 12.9808 - val_loss: 19.2868\n",
      "Epoch 189/800\n",
      "404/404 [==============================] - 0s 74us/step - loss: 22.9742 - val_loss: 17.8945\n",
      "Epoch 190/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 13.8700 - val_loss: 19.2413\n",
      "Epoch 191/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 18.7731 - val_loss: 15.3444\n",
      "Epoch 192/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 12.4782 - val_loss: 14.5227\n",
      "Epoch 193/800\n",
      "404/404 [==============================] - 0s 79us/step - loss: 12.0418 - val_loss: 15.5887\n",
      "Epoch 194/800\n",
      "404/404 [==============================] - 0s 95us/step - loss: 13.2667 - val_loss: 13.4107\n",
      "Epoch 195/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 13.4321 - val_loss: 60.2268\n",
      "Epoch 196/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 35.4605 - val_loss: 16.2730\n",
      "Epoch 197/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 14.1183 - val_loss: 14.0465\n",
      "Epoch 198/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 12.4037 - val_loss: 13.7076\n",
      "Epoch 199/800\n",
      "404/404 [==============================] - 0s 74us/step - loss: 12.0352 - val_loss: 14.5386\n",
      "Epoch 200/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 14.8087 - val_loss: 20.6208\n",
      "Epoch 201/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 12.3128 - val_loss: 27.0551\n",
      "Epoch 202/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 19.1802 - val_loss: 12.6778\n",
      "Epoch 203/800\n",
      "404/404 [==============================] - 0s 101us/step - loss: 10.9226 - val_loss: 18.6302\n",
      "Epoch 204/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 16.4514 - val_loss: 55.2055\n",
      "Epoch 205/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 19.1595 - val_loss: 13.4734\n",
      "Epoch 206/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 11.8903 - val_loss: 14.2801\n",
      "Epoch 207/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 10.5900 - val_loss: 12.5437\n",
      "Epoch 208/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 10.8387 - val_loss: 12.3111\n",
      "Epoch 209/800\n",
      "404/404 [==============================] - 0s 77us/step - loss: 11.0953 - val_loss: 14.6359\n",
      "Epoch 210/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 14.1841 - val_loss: 14.2545\n",
      "Epoch 211/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 12.0662 - val_loss: 24.7516\n",
      "Epoch 212/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 19.9791 - val_loss: 15.4562\n",
      "Epoch 213/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 12.3826 - val_loss: 15.5847\n",
      "Epoch 214/800\n",
      "404/404 [==============================] - 0s 98us/step - loss: 10.5273 - val_loss: 12.3925\n",
      "Epoch 215/800\n",
      "404/404 [==============================] - 0s 78us/step - loss: 9.9487 - val_loss: 16.6438\n",
      "Epoch 216/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 24.0279 - val_loss: 12.8439\n",
      "Epoch 217/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 10.2604 - val_loss: 13.0493\n",
      "Epoch 218/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 10.2907 - val_loss: 12.4067\n",
      "Epoch 219/800\n",
      "404/404 [==============================] - 0s 80us/step - loss: 13.5302 - val_loss: 12.6063\n",
      "Epoch 220/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 10.5193 - val_loss: 13.8491\n",
      "Epoch 221/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 12.9860 - val_loss: 13.3541\n",
      "Epoch 222/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 10.6949 - val_loss: 12.4657\n",
      "Epoch 223/800\n",
      "404/404 [==============================] - 0s 105us/step - loss: 12.7357 - val_loss: 13.6977\n",
      "Epoch 224/800\n",
      "404/404 [==============================] - 0s 77us/step - loss: 11.5468 - val_loss: 15.2396\n",
      "Epoch 225/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 13.1349 - val_loss: 23.6609\n",
      "Epoch 226/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 20.3255 - val_loss: 13.8770\n",
      "Epoch 227/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 9.9646 - val_loss: 12.4266\n",
      "Epoch 228/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 9.7573 - val_loss: 12.2356\n",
      "Epoch 229/800\n",
      "404/404 [==============================] - 0s 76us/step - loss: 12.2318 - val_loss: 15.4633\n",
      "Epoch 230/800\n",
      "404/404 [==============================] - 0s 79us/step - loss: 11.1602 - val_loss: 12.5560\n",
      "Epoch 231/800\n",
      "404/404 [==============================] - 0s 77us/step - loss: 10.0719 - val_loss: 11.9002\n",
      "Epoch 232/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 94us/step - loss: 9.2335 - val_loss: 12.4319\n",
      "Epoch 233/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 8.9550 - val_loss: 22.6947\n",
      "Epoch 234/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 19.2325 - val_loss: 16.9137\n",
      "Epoch 235/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 10.2368 - val_loss: 12.1307\n",
      "Epoch 236/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 13.6698 - val_loss: 19.8092\n",
      "Epoch 237/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 13.5003 - val_loss: 15.3479\n",
      "Epoch 238/800\n",
      "404/404 [==============================] - 0s 113us/step - loss: 10.7815 - val_loss: 11.9373\n",
      "Epoch 239/800\n",
      "404/404 [==============================] - 0s 114us/step - loss: 8.8878 - val_loss: 14.3700\n",
      "Epoch 240/800\n",
      "404/404 [==============================] - 0s 101us/step - loss: 9.7746 - val_loss: 11.4299\n",
      "Epoch 241/800\n",
      "404/404 [==============================] - 0s 74us/step - loss: 8.6919 - val_loss: 11.4303\n",
      "Epoch 242/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 8.5325 - val_loss: 12.5205\n",
      "Epoch 243/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 10.3137 - val_loss: 16.3093\n",
      "Epoch 244/800\n",
      "404/404 [==============================] - 0s 95us/step - loss: 14.0749 - val_loss: 14.1956\n",
      "Epoch 245/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 10.5847 - val_loss: 36.2150\n",
      "Epoch 246/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 25.0586 - val_loss: 18.0576\n",
      "Epoch 247/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 12.7950 - val_loss: 13.0335\n",
      "Epoch 248/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 9.0522 - val_loss: 15.9550\n",
      "Epoch 249/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 11.1963 - val_loss: 11.7956\n",
      "Epoch 250/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 9.4810 - val_loss: 11.7804\n",
      "Epoch 251/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 8.4526 - val_loss: 13.3026\n",
      "Epoch 252/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 8.5171 - val_loss: 11.6977\n",
      "Epoch 253/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 9.2155 - val_loss: 15.5599\n",
      "Epoch 254/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 10.0134 - val_loss: 13.4086\n",
      "Epoch 255/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 10.1336 - val_loss: 11.8927\n",
      "Epoch 256/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 8.0099 - val_loss: 11.1519\n",
      "Epoch 257/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 8.5511 - val_loss: 18.7217\n",
      "Epoch 258/800\n",
      "404/404 [==============================] - 0s 80us/step - loss: 14.7159 - val_loss: 12.0941\n",
      "Epoch 259/800\n",
      "404/404 [==============================] - 0s 80us/step - loss: 11.3225 - val_loss: 12.5398\n",
      "Epoch 260/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 9.6205 - val_loss: 11.4766\n",
      "Epoch 261/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 7.9601 - val_loss: 13.4091\n",
      "Epoch 262/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 13.1618 - val_loss: 12.3204\n",
      "Epoch 263/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 8.0856 - val_loss: 11.0803\n",
      "Epoch 264/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 7.7099 - val_loss: 11.9593\n",
      "Epoch 265/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 7.6613 - val_loss: 12.0772\n",
      "Epoch 266/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 7.8267 - val_loss: 11.2097\n",
      "Epoch 267/800\n",
      "404/404 [==============================] - 0s 74us/step - loss: 8.0292 - val_loss: 12.1557\n",
      "Epoch 268/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 8.7470 - val_loss: 14.7005\n",
      "Epoch 269/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 10.3445 - val_loss: 12.3134\n",
      "Epoch 270/800\n",
      "404/404 [==============================] - 0s 98us/step - loss: 9.4473 - val_loss: 23.4653\n",
      "Epoch 271/800\n",
      "404/404 [==============================] - 0s 80us/step - loss: 11.5954 - val_loss: 11.4853\n",
      "Epoch 272/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 10.5451 - val_loss: 11.4241\n",
      "Epoch 273/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 7.5735 - val_loss: 18.4924\n",
      "Epoch 274/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 12.5853 - val_loss: 12.9384\n",
      "Epoch 275/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 9.1339 - val_loss: 11.7867\n",
      "Epoch 276/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 7.4642 - val_loss: 11.4919\n",
      "Epoch 277/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 7.9954 - val_loss: 16.0953\n",
      "Epoch 278/800\n",
      "404/404 [==============================] - 0s 76us/step - loss: 11.4322 - val_loss: 13.5767\n",
      "Epoch 279/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 8.7720 - val_loss: 11.2292\n",
      "Epoch 280/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 7.3574 - val_loss: 11.1788\n",
      "Epoch 281/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 7.7305 - val_loss: 11.8909\n",
      "Epoch 282/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 7.2970 - val_loss: 12.9450\n",
      "Epoch 283/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 7.6801 - val_loss: 11.8654\n",
      "Epoch 284/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 7.2400 - val_loss: 10.7319\n",
      "Epoch 285/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 8.3393 - val_loss: 16.1539\n",
      "Epoch 286/800\n",
      "404/404 [==============================] - 0s 78us/step - loss: 14.6726 - val_loss: 13.8652\n",
      "Epoch 287/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 10.9997 - val_loss: 14.3044\n",
      "Epoch 288/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 8.7069 - val_loss: 11.7213\n",
      "Epoch 289/800\n",
      "404/404 [==============================] - 0s 99us/step - loss: 7.4095 - val_loss: 11.6358\n",
      "Epoch 290/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 10.2329 - val_loss: 11.1895\n",
      "Epoch 291/800\n",
      "404/404 [==============================] - 0s 75us/step - loss: 8.3398 - val_loss: 11.6109\n",
      "Epoch 292/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 9.1655 - val_loss: 22.4561\n",
      "Epoch 293/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 12.4055 - val_loss: 11.2119\n",
      "Epoch 294/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 8.8684 - val_loss: 11.5983\n",
      "Epoch 295/800\n",
      "404/404 [==============================] - 0s 99us/step - loss: 8.7417 - val_loss: 12.2943\n",
      "Epoch 296/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 7.2183 - val_loss: 12.2361\n",
      "Epoch 297/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 9.7473 - val_loss: 14.0358\n",
      "Epoch 298/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 10.3430 - val_loss: 11.4618\n",
      "Epoch 299/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 8.3569 - val_loss: 14.2373\n",
      "Epoch 300/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 7.1527 - val_loss: 11.2568\n",
      "Epoch 301/800\n",
      "404/404 [==============================] - 0s 105us/step - loss: 6.9799 - val_loss: 11.7868\n",
      "Epoch 302/800\n",
      "404/404 [==============================] - 0s 76us/step - loss: 8.6214 - val_loss: 11.0046\n",
      "Epoch 303/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 8.6106 - val_loss: 11.4042\n",
      "Epoch 304/800\n",
      "404/404 [==============================] - 0s 78us/step - loss: 7.1763 - val_loss: 12.6502\n",
      "Epoch 305/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 9.2614 - val_loss: 13.2667\n",
      "Epoch 306/800\n",
      "404/404 [==============================] - 0s 76us/step - loss: 8.0964 - val_loss: 11.9274\n",
      "Epoch 307/800\n",
      "404/404 [==============================] - 0s 74us/step - loss: 7.1118 - val_loss: 11.8289\n",
      "Epoch 308/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 6.4987 - val_loss: 12.2382\n",
      "Epoch 309/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 6.8977 - val_loss: 11.4965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 310/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 6.7744 - val_loss: 12.1485\n",
      "Epoch 311/800\n",
      "404/404 [==============================] - 0s 80us/step - loss: 10.5567 - val_loss: 10.7603\n",
      "Epoch 312/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 7.5368 - val_loss: 12.5602\n",
      "Epoch 313/800\n",
      "404/404 [==============================] - 0s 95us/step - loss: 8.4857 - val_loss: 12.4553\n",
      "Epoch 314/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 7.4096 - val_loss: 26.8175\n",
      "Epoch 315/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 11.1042 - val_loss: 15.2160\n",
      "Epoch 316/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 17.4242 - val_loss: 11.5268\n",
      "Epoch 317/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 7.0321 - val_loss: 11.1880\n",
      "Epoch 318/800\n",
      "404/404 [==============================] - 0s 117us/step - loss: 6.7627 - val_loss: 11.1825\n",
      "Epoch 319/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 7.7007 - val_loss: 12.3840\n",
      "Epoch 320/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 7.4052 - val_loss: 11.1228\n",
      "Epoch 321/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 7.6028 - val_loss: 13.5868\n",
      "Epoch 322/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 8.3643 - val_loss: 11.2676\n",
      "Epoch 323/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 7.7331 - val_loss: 10.9484\n",
      "Epoch 324/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 6.7631 - val_loss: 12.1384\n",
      "Epoch 325/800\n",
      "404/404 [==============================] - 0s 110us/step - loss: 8.3713 - val_loss: 10.8641\n",
      "Epoch 326/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 7.0696 - val_loss: 12.2487\n",
      "Epoch 327/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 6.6594 - val_loss: 11.3898\n",
      "Epoch 328/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 6.6357 - val_loss: 12.0122\n",
      "Epoch 329/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 7.1463 - val_loss: 12.6386\n",
      "Epoch 330/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 10.2250 - val_loss: 12.3214\n",
      "Epoch 331/800\n",
      "404/404 [==============================] - 0s 123us/step - loss: 6.7228 - val_loss: 14.4337\n",
      "Epoch 332/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 8.8629 - val_loss: 14.2504\n",
      "Epoch 333/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 9.9724 - val_loss: 11.0113\n",
      "Epoch 334/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 7.4839 - val_loss: 13.4485\n",
      "Epoch 335/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 7.3188 - val_loss: 10.8224\n",
      "Epoch 336/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 6.8390 - val_loss: 12.5261\n",
      "Epoch 337/800\n",
      "404/404 [==============================] - 0s 80us/step - loss: 6.3220 - val_loss: 18.2743\n",
      "Epoch 338/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 10.8670 - val_loss: 11.1509\n",
      "Epoch 339/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 8.8318 - val_loss: 10.8153\n",
      "Epoch 340/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 6.4528 - val_loss: 13.5341\n",
      "Epoch 341/800\n",
      "404/404 [==============================] - 0s 101us/step - loss: 7.8447 - val_loss: 12.4720\n",
      "Epoch 342/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 7.3781 - val_loss: 11.0374\n",
      "Epoch 343/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 6.9531 - val_loss: 14.5967\n",
      "Epoch 344/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 8.1562 - val_loss: 10.9809\n",
      "Epoch 345/800\n",
      "404/404 [==============================] - 0s 76us/step - loss: 7.1291 - val_loss: 10.6890\n",
      "Epoch 346/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 6.9351 - val_loss: 10.5120\n",
      "Epoch 347/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 8.1650 - val_loss: 12.1258\n",
      "Epoch 348/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 7.7279 - val_loss: 10.4760\n",
      "Epoch 349/800\n",
      "404/404 [==============================] - 0s 79us/step - loss: 6.3823 - val_loss: 11.0927\n",
      "Epoch 350/800\n",
      "404/404 [==============================] - 0s 79us/step - loss: 8.8654 - val_loss: 10.7132\n",
      "Epoch 351/800\n",
      "404/404 [==============================] - 0s 80us/step - loss: 6.3658 - val_loss: 11.8191\n",
      "Epoch 352/800\n",
      "404/404 [==============================] - 0s 76us/step - loss: 8.3478 - val_loss: 11.4548\n",
      "Epoch 353/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 6.3894 - val_loss: 11.1426\n",
      "Epoch 354/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 6.6686 - val_loss: 10.5371\n",
      "Epoch 355/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 6.1653 - val_loss: 11.4603\n",
      "Epoch 356/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 6.2231 - val_loss: 11.2191\n",
      "Epoch 357/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 7.2638 - val_loss: 11.1149\n",
      "Epoch 358/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 8.0657 - val_loss: 10.3191\n",
      "Epoch 359/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 6.9062 - val_loss: 11.9039\n",
      "Epoch 360/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 6.6564 - val_loss: 10.3454\n",
      "Epoch 361/800\n",
      "404/404 [==============================] - 0s 110us/step - loss: 6.4360 - val_loss: 10.3000\n",
      "Epoch 362/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 5.9956 - val_loss: 10.5096\n",
      "Epoch 363/800\n",
      "404/404 [==============================] - 0s 107us/step - loss: 7.4621 - val_loss: 12.4615\n",
      "Epoch 364/800\n",
      "404/404 [==============================] - 0s 128us/step - loss: 6.5771 - val_loss: 10.8597\n",
      "Epoch 365/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 6.4100 - val_loss: 10.8847\n",
      "Epoch 366/800\n",
      "404/404 [==============================] - 0s 110us/step - loss: 6.8371 - val_loss: 15.5385\n",
      "Epoch 367/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 8.4216 - val_loss: 10.7808\n",
      "Epoch 368/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 6.1236 - val_loss: 11.2528\n",
      "Epoch 369/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 6.5539 - val_loss: 14.3873\n",
      "Epoch 370/800\n",
      "404/404 [==============================] - 0s 79us/step - loss: 7.4145 - val_loss: 14.0566\n",
      "Epoch 371/800\n",
      "404/404 [==============================] - 0s 78us/step - loss: 10.5678 - val_loss: 11.4831\n",
      "Epoch 372/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 8.9949 - val_loss: 10.6879\n",
      "Epoch 373/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 6.7771 - val_loss: 10.9669\n",
      "Epoch 374/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 6.2399 - val_loss: 11.1323\n",
      "Epoch 375/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 7.1316 - val_loss: 11.4782\n",
      "Epoch 376/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 6.9138 - val_loss: 10.8957\n",
      "Epoch 377/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 6.3633 - val_loss: 15.2045\n",
      "Epoch 378/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 8.6513 - val_loss: 10.6430\n",
      "Epoch 379/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 6.2233 - val_loss: 12.7178\n",
      "Epoch 380/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 7.3236 - val_loss: 10.9026\n",
      "Epoch 381/800\n",
      "404/404 [==============================] - 0s 101us/step - loss: 6.1747 - val_loss: 10.4400\n",
      "Epoch 382/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 6.6787 - val_loss: 11.0241\n",
      "Epoch 383/800\n",
      "404/404 [==============================] - 0s 77us/step - loss: 6.1276 - val_loss: 11.7516\n",
      "Epoch 384/800\n",
      "404/404 [==============================] - 0s 98us/step - loss: 7.6701 - val_loss: 11.5294\n",
      "Epoch 385/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 6.1124 - val_loss: 11.2983\n",
      "Epoch 386/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 6.3058 - val_loss: 10.7489\n",
      "Epoch 387/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 5.9170 - val_loss: 11.5887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 388/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 6.3393 - val_loss: 10.6700\n",
      "Epoch 389/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 6.5484 - val_loss: 11.5753\n",
      "Epoch 390/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 6.1081 - val_loss: 10.7587\n",
      "Epoch 391/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 5.9756 - val_loss: 10.5618\n",
      "Epoch 392/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 6.9299 - val_loss: 10.6459\n",
      "Epoch 393/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 6.0716 - val_loss: 12.3887\n",
      "Epoch 394/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 6.7889 - val_loss: 10.8266\n",
      "Epoch 395/800\n",
      "404/404 [==============================] - 0s 80us/step - loss: 5.8754 - val_loss: 11.3565\n",
      "Epoch 396/800\n",
      "404/404 [==============================] - 0s 98us/step - loss: 7.3583 - val_loss: 11.6683\n",
      "Epoch 397/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 7.2418 - val_loss: 15.9076\n",
      "Epoch 398/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 10.0753 - val_loss: 11.0054\n",
      "Epoch 399/800\n",
      "404/404 [==============================] - 0s 70us/step - loss: 5.9102 - val_loss: 11.8156\n",
      "Epoch 400/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 6.1767 - val_loss: 12.5806\n",
      "Epoch 401/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 9.5630 - val_loss: 10.5769\n",
      "Epoch 402/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 6.0745 - val_loss: 11.6913\n",
      "Epoch 403/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 7.2397 - val_loss: 19.1865\n",
      "Epoch 404/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 13.0854 - val_loss: 12.0604\n",
      "Epoch 405/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 6.2023 - val_loss: 10.6413\n",
      "Epoch 406/800\n",
      "404/404 [==============================] - 0s 118us/step - loss: 5.8427 - val_loss: 10.7024\n",
      "Epoch 407/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 6.3331 - val_loss: 11.5502\n",
      "Epoch 408/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 5.9983 - val_loss: 10.8241\n",
      "Epoch 409/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 6.1387 - val_loss: 10.8235\n",
      "Epoch 410/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 5.7192 - val_loss: 10.7610\n",
      "Epoch 411/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 5.8541 - val_loss: 10.1485\n",
      "Epoch 412/800\n",
      "404/404 [==============================] - 0s 124us/step - loss: 6.0562 - val_loss: 10.6517\n",
      "Epoch 413/800\n",
      "404/404 [==============================] - 0s 78us/step - loss: 5.7836 - val_loss: 10.4222\n",
      "Epoch 414/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 6.0903 - val_loss: 10.6732\n",
      "Epoch 415/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 5.8104 - val_loss: 11.9652\n",
      "Epoch 416/800\n",
      "404/404 [==============================] - 0s 99us/step - loss: 6.1870 - val_loss: 15.9999\n",
      "Epoch 417/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 8.5844 - val_loss: 14.3321\n",
      "Epoch 418/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 8.4889 - val_loss: 11.9937\n",
      "Epoch 419/800\n",
      "404/404 [==============================] - 0s 75us/step - loss: 6.0953 - val_loss: 11.0235\n",
      "Epoch 420/800\n",
      "404/404 [==============================] - 0s 95us/step - loss: 5.6315 - val_loss: 11.8933\n",
      "Epoch 421/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 6.2629 - val_loss: 10.6512\n",
      "Epoch 422/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 6.2506 - val_loss: 12.5550\n",
      "Epoch 423/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 6.2720 - val_loss: 11.0793\n",
      "Epoch 424/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 5.9108 - val_loss: 14.3460\n",
      "Epoch 425/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 7.6207 - val_loss: 15.1961\n",
      "Epoch 426/800\n",
      "404/404 [==============================] - 0s 98us/step - loss: 6.6453 - val_loss: 10.3909\n",
      "Epoch 427/800\n",
      "404/404 [==============================] - 0s 101us/step - loss: 5.4546 - val_loss: 11.1045\n",
      "Epoch 428/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 6.0004 - val_loss: 14.3336\n",
      "Epoch 429/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 6.5593 - val_loss: 11.9298\n",
      "Epoch 430/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 5.9018 - val_loss: 12.2735\n",
      "Epoch 431/800\n",
      "404/404 [==============================] - 0s 98us/step - loss: 7.7797 - val_loss: 11.5772\n",
      "Epoch 432/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 5.7619 - val_loss: 10.8882\n",
      "Epoch 433/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 6.0410 - val_loss: 10.9020\n",
      "Epoch 434/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 7.0927 - val_loss: 9.9660\n",
      "Epoch 435/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 5.6517 - val_loss: 11.1623\n",
      "Epoch 436/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 5.5537 - val_loss: 11.4926\n",
      "Epoch 437/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 5.5682 - val_loss: 11.9505\n",
      "Epoch 438/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 7.2365 - val_loss: 10.6730\n",
      "Epoch 439/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 6.5031 - val_loss: 10.2343\n",
      "Epoch 440/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 5.3827 - val_loss: 10.7389\n",
      "Epoch 441/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 5.9130 - val_loss: 10.7774\n",
      "Epoch 442/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 6.0199 - val_loss: 11.0747\n",
      "Epoch 443/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 7.0289 - val_loss: 11.0001\n",
      "Epoch 444/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 5.7128 - val_loss: 10.4929\n",
      "Epoch 445/800\n",
      "404/404 [==============================] - 0s 105us/step - loss: 5.6057 - val_loss: 11.3184\n",
      "Epoch 446/800\n",
      "404/404 [==============================] - 0s 104us/step - loss: 5.8196 - val_loss: 16.6166\n",
      "Epoch 447/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 12.7243 - val_loss: 10.6425\n",
      "Epoch 448/800\n",
      "404/404 [==============================] - 0s 77us/step - loss: 5.7403 - val_loss: 10.2349\n",
      "Epoch 449/800\n",
      "404/404 [==============================] - 0s 79us/step - loss: 6.6342 - val_loss: 11.9632\n",
      "Epoch 450/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 6.4631 - val_loss: 10.6134\n",
      "Epoch 451/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 5.6633 - val_loss: 10.5473\n",
      "Epoch 452/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 5.4159 - val_loss: 10.4247\n",
      "Epoch 453/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 5.3360 - val_loss: 10.9836\n",
      "Epoch 454/800\n",
      "404/404 [==============================] - 0s 75us/step - loss: 6.3118 - val_loss: 14.6579\n",
      "Epoch 455/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 7.5613 - val_loss: 10.8096\n",
      "Epoch 456/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 6.1036 - val_loss: 13.0062\n",
      "Epoch 457/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 6.0025 - val_loss: 11.0017\n",
      "Epoch 458/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 5.3629 - val_loss: 15.8723\n",
      "Epoch 459/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 6.9389 - val_loss: 10.3185\n",
      "Epoch 460/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 6.3363 - val_loss: 10.5907\n",
      "Epoch 461/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 5.2721 - val_loss: 10.9367\n",
      "Epoch 462/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 6.7485 - val_loss: 10.4984\n",
      "Epoch 463/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 5.2438 - val_loss: 10.7102\n",
      "Epoch 464/800\n",
      "404/404 [==============================] - 0s 74us/step - loss: 6.6254 - val_loss: 10.9978\n",
      "Epoch 465/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 5.6529 - val_loss: 12.2983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 466/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 9.9955 - val_loss: 11.2386\n",
      "Epoch 467/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 5.4494 - val_loss: 11.9736\n",
      "Epoch 468/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 5.8390 - val_loss: 10.2959\n",
      "Epoch 469/800\n",
      "404/404 [==============================] - 0s 79us/step - loss: 5.4558 - val_loss: 13.0238\n",
      "Epoch 470/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 6.1947 - val_loss: 12.0635\n",
      "Epoch 471/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 5.9283 - val_loss: 10.5638\n",
      "Epoch 472/800\n",
      "404/404 [==============================] - 0s 104us/step - loss: 5.6290 - val_loss: 10.7916\n",
      "Epoch 473/800\n",
      "404/404 [==============================] - 0s 75us/step - loss: 5.7032 - val_loss: 10.9654\n",
      "Epoch 474/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 6.4845 - val_loss: 10.4584\n",
      "Epoch 475/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 5.5498 - val_loss: 12.1657\n",
      "Epoch 476/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 5.7523 - val_loss: 10.4210\n",
      "Epoch 477/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 5.4804 - val_loss: 11.5058\n",
      "Epoch 478/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 7.3544 - val_loss: 10.3946\n",
      "Epoch 479/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 5.4791 - val_loss: 12.4602\n",
      "Epoch 480/800\n",
      "404/404 [==============================] - 0s 95us/step - loss: 6.1082 - val_loss: 11.7256\n",
      "Epoch 481/800\n",
      "404/404 [==============================] - 0s 95us/step - loss: 5.9534 - val_loss: 10.3893\n",
      "Epoch 482/800\n",
      "404/404 [==============================] - 0s 107us/step - loss: 5.5980 - val_loss: 10.5174\n",
      "Epoch 483/800\n",
      "404/404 [==============================] - 0s 99us/step - loss: 5.3994 - val_loss: 11.2940\n",
      "Epoch 484/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 5.7452 - val_loss: 10.9330\n",
      "Epoch 485/800\n",
      "404/404 [==============================] - 0s 101us/step - loss: 5.0088 - val_loss: 11.0117\n",
      "Epoch 486/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 6.3530 - val_loss: 11.3441\n",
      "Epoch 487/800\n",
      "404/404 [==============================] - 0s 149us/step - loss: 6.2341 - val_loss: 10.2461\n",
      "Epoch 488/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 5.3382 - val_loss: 11.1583\n",
      "Epoch 489/800\n",
      "404/404 [==============================] - 0s 105us/step - loss: 5.8000 - val_loss: 10.6053\n",
      "Epoch 490/800\n",
      "404/404 [==============================] - 0s 98us/step - loss: 5.1685 - val_loss: 15.2839\n",
      "Epoch 491/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 6.8104 - val_loss: 12.6879\n",
      "Epoch 492/800\n",
      "404/404 [==============================] - 0s 109us/step - loss: 5.9391 - val_loss: 10.7616\n",
      "Epoch 493/800\n",
      "404/404 [==============================] - 0s 99us/step - loss: 5.4335 - val_loss: 14.7789\n",
      "Epoch 494/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 7.9799 - val_loss: 12.1376\n",
      "Epoch 495/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 5.3047 - val_loss: 10.3176\n",
      "Epoch 496/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 5.1984 - val_loss: 10.4336\n",
      "Epoch 497/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 5.3007 - val_loss: 11.0462\n",
      "Epoch 498/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 6.1310 - val_loss: 11.5833\n",
      "Epoch 499/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 6.5024 - val_loss: 10.2344\n",
      "Epoch 500/800\n",
      "404/404 [==============================] - 0s 79us/step - loss: 5.1350 - val_loss: 10.2338\n",
      "Epoch 501/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 5.0557 - val_loss: 10.4544\n",
      "Epoch 502/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 6.1016 - val_loss: 11.4387\n",
      "Epoch 503/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 6.6275 - val_loss: 11.3702\n",
      "Epoch 504/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 5.1329 - val_loss: 10.2243\n",
      "Epoch 505/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 5.1121 - val_loss: 10.3925\n",
      "Epoch 506/800\n",
      "404/404 [==============================] - 0s 133us/step - loss: 5.6835 - val_loss: 10.8775\n",
      "Epoch 507/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 5.1089 - val_loss: 12.6958\n",
      "Epoch 508/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 6.2897 - val_loss: 11.9677\n",
      "Epoch 509/800\n",
      "404/404 [==============================] - 0s 76us/step - loss: 6.0859 - val_loss: 10.7564\n",
      "Epoch 510/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 7.5911 - val_loss: 10.3257\n",
      "Epoch 511/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 4.9888 - val_loss: 10.3705\n",
      "Epoch 512/800\n",
      "404/404 [==============================] - 0s 108us/step - loss: 5.0114 - val_loss: 9.9940\n",
      "Epoch 513/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 5.1861 - val_loss: 10.8686\n",
      "Epoch 514/800\n",
      "404/404 [==============================] - 0s 157us/step - loss: 5.0013 - val_loss: 11.0848\n",
      "Epoch 515/800\n",
      "404/404 [==============================] - 0s 141us/step - loss: 5.6141 - val_loss: 10.6214\n",
      "Epoch 516/800\n",
      "404/404 [==============================] - 0s 104us/step - loss: 5.0291 - val_loss: 10.2876\n",
      "Epoch 517/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 5.0039 - val_loss: 11.5206\n",
      "Epoch 518/800\n",
      "404/404 [==============================] - 0s 110us/step - loss: 5.5206 - val_loss: 11.1809\n",
      "Epoch 519/800\n",
      "404/404 [==============================] - 0s 105us/step - loss: 6.0595 - val_loss: 12.1458\n",
      "Epoch 520/800\n",
      "404/404 [==============================] - 0s 117us/step - loss: 5.4790 - val_loss: 10.3003\n",
      "Epoch 521/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 5.4544 - val_loss: 10.5761\n",
      "Epoch 522/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 4.9176 - val_loss: 11.3567\n",
      "Epoch 523/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 4.9716 - val_loss: 10.3581\n",
      "Epoch 524/800\n",
      "404/404 [==============================] - 0s 95us/step - loss: 4.8914 - val_loss: 10.3237\n",
      "Epoch 525/800\n",
      "404/404 [==============================] - 0s 133us/step - loss: 4.9168 - val_loss: 10.3187\n",
      "Epoch 526/800\n",
      "404/404 [==============================] - 0s 172us/step - loss: 4.9614 - val_loss: 10.8728\n",
      "Epoch 527/800\n",
      "404/404 [==============================] - 0s 123us/step - loss: 6.3238 - val_loss: 11.8073\n",
      "Epoch 528/800\n",
      "404/404 [==============================] - 0s 147us/step - loss: 5.2869 - val_loss: 10.9326\n",
      "Epoch 529/800\n",
      "404/404 [==============================] - 0s 173us/step - loss: 4.7994 - val_loss: 10.0381\n",
      "Epoch 530/800\n",
      "404/404 [==============================] - 0s 112us/step - loss: 4.9849 - val_loss: 13.6598\n",
      "Epoch 531/800\n",
      "404/404 [==============================] - 0s 149us/step - loss: 9.0678 - val_loss: 11.9910\n",
      "Epoch 532/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 6.1261 - val_loss: 10.5460\n",
      "Epoch 533/800\n",
      "404/404 [==============================] - 0s 142us/step - loss: 5.3964 - val_loss: 10.1552\n",
      "Epoch 534/800\n",
      "404/404 [==============================] - 0s 113us/step - loss: 5.3652 - val_loss: 10.8047\n",
      "Epoch 535/800\n",
      "404/404 [==============================] - 0s 146us/step - loss: 5.9124 - val_loss: 10.0023\n",
      "Epoch 536/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 4.9804 - val_loss: 10.1062\n",
      "Epoch 537/800\n",
      "404/404 [==============================] - 0s 107us/step - loss: 5.3192 - val_loss: 12.4972\n",
      "Epoch 538/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 5.7921 - val_loss: 11.0432\n",
      "Epoch 539/800\n",
      "404/404 [==============================] - 0s 111us/step - loss: 4.9902 - val_loss: 11.6787\n",
      "Epoch 540/800\n",
      "404/404 [==============================] - 0s 158us/step - loss: 5.3994 - val_loss: 11.1099\n",
      "Epoch 541/800\n",
      "404/404 [==============================] - 0s 150us/step - loss: 6.4250 - val_loss: 12.8268\n",
      "Epoch 542/800\n",
      "404/404 [==============================] - 0s 74us/step - loss: 5.3916 - val_loss: 10.4921\n",
      "Epoch 543/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 82us/step - loss: 5.0206 - val_loss: 10.0916\n",
      "Epoch 544/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 5.0066 - val_loss: 11.3206\n",
      "Epoch 545/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 5.8426 - val_loss: 11.1513\n",
      "Epoch 546/800\n",
      "404/404 [==============================] - 0s 104us/step - loss: 5.9572 - val_loss: 17.2960\n",
      "Epoch 547/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 10.5144 - val_loss: 10.6380\n",
      "Epoch 548/800\n",
      "404/404 [==============================] - 0s 95us/step - loss: 4.9036 - val_loss: 10.4050\n",
      "Epoch 549/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 5.0052 - val_loss: 10.7333\n",
      "Epoch 550/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 4.8566 - val_loss: 10.7256\n",
      "Epoch 551/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 5.0841 - val_loss: 14.3030\n",
      "Epoch 552/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 6.4407 - val_loss: 10.1232\n",
      "Epoch 553/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 5.9555 - val_loss: 12.0924\n",
      "Epoch 554/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 6.3822 - val_loss: 10.3475\n",
      "Epoch 555/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 4.9518 - val_loss: 10.1080\n",
      "Epoch 556/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 4.9998 - val_loss: 10.2994\n",
      "Epoch 557/800\n",
      "404/404 [==============================] - 0s 101us/step - loss: 5.2009 - val_loss: 10.2230\n",
      "Epoch 558/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 5.3088 - val_loss: 11.0732\n",
      "Epoch 559/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 5.5480 - val_loss: 10.4233\n",
      "Epoch 560/800\n",
      "404/404 [==============================] - 0s 79us/step - loss: 4.7388 - val_loss: 11.0672\n",
      "Epoch 561/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 5.3121 - val_loss: 10.2511\n",
      "Epoch 562/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 6.4407 - val_loss: 11.4690\n",
      "Epoch 563/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 5.2294 - val_loss: 9.9801\n",
      "Epoch 564/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 4.7874 - val_loss: 10.4050\n",
      "Epoch 565/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 5.3006 - val_loss: 20.3111\n",
      "Epoch 566/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 7.5387 - val_loss: 10.3995\n",
      "Epoch 567/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 5.1064 - val_loss: 9.8329\n",
      "Epoch 568/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 5.0677 - val_loss: 10.2426\n",
      "Epoch 569/800\n",
      "404/404 [==============================] - 0s 143us/step - loss: 4.9949 - val_loss: 10.4540\n",
      "Epoch 570/800\n",
      "404/404 [==============================] - 0s 128us/step - loss: 5.8234 - val_loss: 11.4196\n",
      "Epoch 571/800\n",
      "404/404 [==============================] - 0s 114us/step - loss: 5.8947 - val_loss: 10.8482\n",
      "Epoch 572/800\n",
      "404/404 [==============================] - 0s 108us/step - loss: 4.8391 - val_loss: 10.5372\n",
      "Epoch 573/800\n",
      "404/404 [==============================] - 0s 124us/step - loss: 4.7839 - val_loss: 10.3781\n",
      "Epoch 574/800\n",
      "404/404 [==============================] - 0s 122us/step - loss: 4.6131 - val_loss: 9.9000\n",
      "Epoch 575/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 4.8929 - val_loss: 10.2520\n",
      "Epoch 576/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 4.6430 - val_loss: 10.3886\n",
      "Epoch 577/800\n",
      "404/404 [==============================] - 0s 128us/step - loss: 4.8426 - val_loss: 10.2661\n",
      "Epoch 578/800\n",
      "404/404 [==============================] - 0s 141us/step - loss: 4.7489 - val_loss: 10.5139\n",
      "Epoch 579/800\n",
      "404/404 [==============================] - 0s 120us/step - loss: 4.7169 - val_loss: 10.0953\n",
      "Epoch 580/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 4.6118 - val_loss: 10.9621\n",
      "Epoch 581/800\n",
      "404/404 [==============================] - 0s 115us/step - loss: 5.0603 - val_loss: 10.1540\n",
      "Epoch 582/800\n",
      "404/404 [==============================] - 0s 117us/step - loss: 5.3624 - val_loss: 10.3002\n",
      "Epoch 583/800\n",
      "404/404 [==============================] - 0s 123us/step - loss: 5.0053 - val_loss: 10.9823\n",
      "Epoch 584/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 4.7665 - val_loss: 10.5111\n",
      "Epoch 585/800\n",
      "404/404 [==============================] - 0s 98us/step - loss: 4.8035 - val_loss: 10.2700\n",
      "Epoch 586/800\n",
      "404/404 [==============================] - 0s 80us/step - loss: 4.6237 - val_loss: 10.1066\n",
      "Epoch 587/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 4.6554 - val_loss: 9.8528\n",
      "Epoch 588/800\n",
      "404/404 [==============================] - 0s 101us/step - loss: 4.8054 - val_loss: 10.0743\n",
      "Epoch 589/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 5.2159 - val_loss: 11.4896\n",
      "Epoch 590/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 8.7524 - val_loss: 10.0242\n",
      "Epoch 591/800\n",
      "404/404 [==============================] - 0s 110us/step - loss: 4.8356 - val_loss: 11.4316\n",
      "Epoch 592/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 5.4878 - val_loss: 10.2247\n",
      "Epoch 593/800\n",
      "404/404 [==============================] - 0s 110us/step - loss: 4.6325 - val_loss: 9.9586\n",
      "Epoch 594/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 4.6127 - val_loss: 9.8703\n",
      "Epoch 595/800\n",
      "404/404 [==============================] - 0s 107us/step - loss: 4.8083 - val_loss: 10.5398\n",
      "Epoch 596/800\n",
      "404/404 [==============================] - 0s 101us/step - loss: 5.3536 - val_loss: 9.5278\n",
      "Epoch 597/800\n",
      "404/404 [==============================] - 0s 108us/step - loss: 4.9522 - val_loss: 9.8586\n",
      "Epoch 598/800\n",
      "404/404 [==============================] - 0s 111us/step - loss: 4.7326 - val_loss: 10.8093\n",
      "Epoch 599/800\n",
      "404/404 [==============================] - 0s 116us/step - loss: 4.7656 - val_loss: 11.3622\n",
      "Epoch 600/800\n",
      "404/404 [==============================] - 0s 126us/step - loss: 5.3541 - val_loss: 10.7386\n",
      "Epoch 601/800\n",
      "404/404 [==============================] - 0s 121us/step - loss: 4.7515 - val_loss: 11.7296\n",
      "Epoch 602/800\n",
      "404/404 [==============================] - 0s 124us/step - loss: 5.4333 - val_loss: 10.6594\n",
      "Epoch 603/800\n",
      "404/404 [==============================] - 0s 110us/step - loss: 4.6005 - val_loss: 10.9556\n",
      "Epoch 604/800\n",
      "404/404 [==============================] - 0s 113us/step - loss: 5.1094 - val_loss: 9.8634\n",
      "Epoch 605/800\n",
      "404/404 [==============================] - 0s 117us/step - loss: 4.6760 - val_loss: 11.3843\n",
      "Epoch 606/800\n",
      "404/404 [==============================] - 0s 146us/step - loss: 6.0100 - val_loss: 10.6814\n",
      "Epoch 607/800\n",
      "404/404 [==============================] - 0s 168us/step - loss: 4.9481 - val_loss: 10.3821\n",
      "Epoch 608/800\n",
      "404/404 [==============================] - 0s 126us/step - loss: 4.6797 - val_loss: 12.2256\n",
      "Epoch 609/800\n",
      "404/404 [==============================] - 0s 98us/step - loss: 5.4828 - val_loss: 10.7590\n",
      "Epoch 610/800\n",
      "404/404 [==============================] - 0s 111us/step - loss: 5.5859 - val_loss: 10.5755\n",
      "Epoch 611/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 5.0463 - val_loss: 9.8990\n",
      "Epoch 612/800\n",
      "404/404 [==============================] - 0s 95us/step - loss: 4.5377 - val_loss: 9.7352\n",
      "Epoch 613/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 4.7941 - val_loss: 10.1986\n",
      "Epoch 614/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 4.5641 - val_loss: 10.3138\n",
      "Epoch 615/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 5.7409 - val_loss: 9.7948\n",
      "Epoch 616/800\n",
      "404/404 [==============================] - 0s 122us/step - loss: 4.7348 - val_loss: 10.4521\n",
      "Epoch 617/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 4.9056 - val_loss: 10.6206\n",
      "Epoch 618/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 5.3187 - val_loss: 11.5180\n",
      "Epoch 619/800\n",
      "404/404 [==============================] - 0s 110us/step - loss: 5.4119 - val_loss: 9.7319\n",
      "Epoch 620/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 4.5350 - val_loss: 10.4616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 621/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 5.1186 - val_loss: 10.0917\n",
      "Epoch 622/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 4.6320 - val_loss: 13.4808\n",
      "Epoch 623/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 6.9238 - val_loss: 10.0342\n",
      "Epoch 624/800\n",
      "404/404 [==============================] - 0s 108us/step - loss: 5.0094 - val_loss: 11.5558\n",
      "Epoch 625/800\n",
      "404/404 [==============================] - 0s 119us/step - loss: 4.8195 - val_loss: 10.4302\n",
      "Epoch 626/800\n",
      "404/404 [==============================] - 0s 101us/step - loss: 4.4807 - val_loss: 9.8913\n",
      "Epoch 627/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 4.8445 - val_loss: 10.2200\n",
      "Epoch 628/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 4.5162 - val_loss: 9.7265\n",
      "Epoch 629/800\n",
      "404/404 [==============================] - 0s 130us/step - loss: 5.0124 - val_loss: 14.4927\n",
      "Epoch 630/800\n",
      "404/404 [==============================] - 0s 105us/step - loss: 7.6242 - val_loss: 10.0403\n",
      "Epoch 631/800\n",
      "404/404 [==============================] - 0s 105us/step - loss: 5.3457 - val_loss: 9.9008\n",
      "Epoch 632/800\n",
      "404/404 [==============================] - 0s 95us/step - loss: 5.1416 - val_loss: 10.6685\n",
      "Epoch 633/800\n",
      "404/404 [==============================] - 0s 119us/step - loss: 5.2314 - val_loss: 13.5865\n",
      "Epoch 634/800\n",
      "404/404 [==============================] - 0s 111us/step - loss: 5.1169 - val_loss: 10.7241\n",
      "Epoch 635/800\n",
      "404/404 [==============================] - 0s 105us/step - loss: 4.8501 - val_loss: 10.5177\n",
      "Epoch 636/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 4.8582 - val_loss: 11.7979\n",
      "Epoch 637/800\n",
      "404/404 [==============================] - 0s 119us/step - loss: 4.9204 - val_loss: 9.8160\n",
      "Epoch 638/800\n",
      "404/404 [==============================] - 0s 104us/step - loss: 4.6556 - val_loss: 10.7564\n",
      "Epoch 639/800\n",
      "404/404 [==============================] - 0s 115us/step - loss: 4.5899 - val_loss: 9.8459\n",
      "Epoch 640/800\n",
      "404/404 [==============================] - 0s 111us/step - loss: 4.4326 - val_loss: 10.2911\n",
      "Epoch 641/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 4.7864 - val_loss: 10.0437\n",
      "Epoch 642/800\n",
      "404/404 [==============================] - 0s 108us/step - loss: 4.4399 - val_loss: 10.6987\n",
      "Epoch 643/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 4.5657 - val_loss: 9.7622\n",
      "Epoch 644/800\n",
      "404/404 [==============================] - 0s 98us/step - loss: 6.4261 - val_loss: 12.2787\n",
      "Epoch 645/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 5.2891 - val_loss: 9.8161\n",
      "Epoch 646/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 4.5646 - val_loss: 10.8217\n",
      "Epoch 647/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 6.0123 - val_loss: 10.1990\n",
      "Epoch 648/800\n",
      "404/404 [==============================] - 0s 110us/step - loss: 4.7445 - val_loss: 9.7503\n",
      "Epoch 649/800\n",
      "404/404 [==============================] - 0s 124us/step - loss: 4.4040 - val_loss: 9.9154\n",
      "Epoch 650/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 4.3368 - val_loss: 9.7021\n",
      "Epoch 651/800\n",
      "404/404 [==============================] - 0s 81us/step - loss: 4.7334 - val_loss: 9.9305\n",
      "Epoch 652/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 4.3673 - val_loss: 10.4907\n",
      "Epoch 653/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 4.4979 - val_loss: 10.0540\n",
      "Epoch 654/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 5.0062 - val_loss: 10.5182\n",
      "Epoch 655/800\n",
      "404/404 [==============================] - 0s 104us/step - loss: 4.9515 - val_loss: 10.7514\n",
      "Epoch 656/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 5.7524 - val_loss: 11.2253\n",
      "Epoch 657/800\n",
      "404/404 [==============================] - 0s 112us/step - loss: 4.4361 - val_loss: 11.1302\n",
      "Epoch 658/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 4.5728 - val_loss: 9.5945\n",
      "Epoch 659/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 5.2347 - val_loss: 9.9779\n",
      "Epoch 660/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 4.3796 - val_loss: 10.5568\n",
      "Epoch 661/800\n",
      "404/404 [==============================] - 0s 101us/step - loss: 4.8786 - val_loss: 10.7406\n",
      "Epoch 662/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 4.5234 - val_loss: 10.1351\n",
      "Epoch 663/800\n",
      "404/404 [==============================] - 0s 99us/step - loss: 4.3785 - val_loss: 10.2514\n",
      "Epoch 664/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 4.9153 - val_loss: 11.0659\n",
      "Epoch 665/800\n",
      "404/404 [==============================] - 0s 108us/step - loss: 4.6080 - val_loss: 10.5447\n",
      "Epoch 666/800\n",
      "404/404 [==============================] - 0s 116us/step - loss: 4.8136 - val_loss: 13.1695\n",
      "Epoch 667/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 5.3056 - val_loss: 9.8528\n",
      "Epoch 668/800\n",
      "404/404 [==============================] - 0s 99us/step - loss: 4.7455 - val_loss: 10.5838\n",
      "Epoch 669/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 4.8959 - val_loss: 11.5059\n",
      "Epoch 670/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 5.0332 - val_loss: 11.6600\n",
      "Epoch 671/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 4.8495 - val_loss: 10.9639\n",
      "Epoch 672/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 5.7021 - val_loss: 13.8986\n",
      "Epoch 673/800\n",
      "404/404 [==============================] - 0s 121us/step - loss: 5.8985 - val_loss: 9.8861\n",
      "Epoch 674/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 4.4117 - val_loss: 10.8587\n",
      "Epoch 675/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 4.4632 - val_loss: 10.5031\n",
      "Epoch 676/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 4.3662 - val_loss: 10.3682\n",
      "Epoch 677/800\n",
      "404/404 [==============================] - 0s 115us/step - loss: 4.6689 - val_loss: 10.2339\n",
      "Epoch 678/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 4.5141 - val_loss: 10.8938\n",
      "Epoch 679/800\n",
      "404/404 [==============================] - 0s 114us/step - loss: 4.4564 - val_loss: 9.8015\n",
      "Epoch 680/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 4.3607 - val_loss: 10.1043\n",
      "Epoch 681/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 5.6015 - val_loss: 9.8444\n",
      "Epoch 682/800\n",
      "404/404 [==============================] - 0s 112us/step - loss: 4.5415 - val_loss: 9.6643\n",
      "Epoch 683/800\n",
      "404/404 [==============================] - 0s 109us/step - loss: 4.8288 - val_loss: 9.7208\n",
      "Epoch 684/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 4.2954 - val_loss: 12.8122\n",
      "Epoch 685/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 6.1319 - val_loss: 10.6750\n",
      "Epoch 686/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 4.4714 - val_loss: 10.0415\n",
      "Epoch 687/800\n",
      "404/404 [==============================] - 0s 122us/step - loss: 4.3674 - val_loss: 10.8021\n",
      "Epoch 688/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 5.0555 - val_loss: 10.6021\n",
      "Epoch 689/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 4.9898 - val_loss: 10.7286\n",
      "Epoch 690/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 4.3928 - val_loss: 9.7727\n",
      "Epoch 691/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 4.3533 - val_loss: 9.9890\n",
      "Epoch 692/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 4.5565 - val_loss: 10.1554\n",
      "Epoch 693/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 4.4452 - val_loss: 11.4225\n",
      "Epoch 694/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 4.6677 - val_loss: 10.6167\n",
      "Epoch 695/800\n",
      "404/404 [==============================] - 0s 115us/step - loss: 4.4358 - val_loss: 10.6353\n",
      "Epoch 696/800\n",
      "404/404 [==============================] - 0s 105us/step - loss: 4.6971 - val_loss: 9.5617\n",
      "Epoch 697/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 4.4258 - val_loss: 10.9770\n",
      "Epoch 698/800\n",
      "404/404 [==============================] - 0s 101us/step - loss: 4.4833 - val_loss: 12.6005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 699/800\n",
      "404/404 [==============================] - 0s 101us/step - loss: 6.0252 - val_loss: 10.8589\n",
      "Epoch 700/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 4.7141 - val_loss: 10.6774\n",
      "Epoch 701/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 4.2756 - val_loss: 10.5630\n",
      "Epoch 702/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 5.0312 - val_loss: 9.9642\n",
      "Epoch 703/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 4.4643 - val_loss: 10.1827\n",
      "Epoch 704/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 4.3277 - val_loss: 10.1173\n",
      "Epoch 705/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 4.4017 - val_loss: 10.0884\n",
      "Epoch 706/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 4.2175 - val_loss: 9.7396\n",
      "Epoch 707/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 4.3140 - val_loss: 9.7469\n",
      "Epoch 708/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 4.2142 - val_loss: 10.0111\n",
      "Epoch 709/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 4.4625 - val_loss: 9.8110\n",
      "Epoch 710/800\n",
      "404/404 [==============================] - 0s 79us/step - loss: 4.2253 - val_loss: 9.5211\n",
      "Epoch 711/800\n",
      "404/404 [==============================] - 0s 78us/step - loss: 4.2098 - val_loss: 10.2653\n",
      "Epoch 712/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 4.4301 - val_loss: 9.6647\n",
      "Epoch 713/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 4.9034 - val_loss: 9.5527\n",
      "Epoch 714/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 4.2442 - val_loss: 9.9723\n",
      "Epoch 715/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 4.6223 - val_loss: 9.9605\n",
      "Epoch 716/800\n",
      "404/404 [==============================] - 0s 99us/step - loss: 4.2264 - val_loss: 10.3084\n",
      "Epoch 717/800\n",
      "404/404 [==============================] - 0s 91us/step - loss: 4.8486 - val_loss: 9.5967\n",
      "Epoch 718/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 4.5693 - val_loss: 10.0851\n",
      "Epoch 719/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 4.5765 - val_loss: 10.7480\n",
      "Epoch 720/800\n",
      "404/404 [==============================] - 0s 82us/step - loss: 4.4470 - val_loss: 9.7907\n",
      "Epoch 721/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 4.2968 - val_loss: 10.2435\n",
      "Epoch 722/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 4.9339 - val_loss: 12.2971\n",
      "Epoch 723/800\n",
      "404/404 [==============================] - 0s 92us/step - loss: 5.3238 - val_loss: 10.0381\n",
      "Epoch 724/800\n",
      "404/404 [==============================] - 0s 110us/step - loss: 4.4720 - val_loss: 9.5624\n",
      "Epoch 725/800\n",
      "404/404 [==============================] - 0s 117us/step - loss: 4.3021 - val_loss: 10.2486\n",
      "Epoch 726/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 4.6479 - val_loss: 10.0981\n",
      "Epoch 727/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 4.2061 - val_loss: 9.6489\n",
      "Epoch 728/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 4.0833 - val_loss: 11.2456\n",
      "Epoch 729/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 5.1733 - val_loss: 9.5013\n",
      "Epoch 730/800\n",
      "404/404 [==============================] - 0s 99us/step - loss: 4.2854 - val_loss: 10.8598\n",
      "Epoch 731/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 4.4917 - val_loss: 10.3092\n",
      "Epoch 732/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 4.4409 - val_loss: 9.8140\n",
      "Epoch 733/800\n",
      "404/404 [==============================] - 0s 107us/step - loss: 4.0967 - val_loss: 10.4185\n",
      "Epoch 734/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 4.2351 - val_loss: 11.8001\n",
      "Epoch 735/800\n",
      "404/404 [==============================] - 0s 128us/step - loss: 4.8492 - val_loss: 10.6810\n",
      "Epoch 736/800\n",
      "404/404 [==============================] - 0s 117us/step - loss: 4.2571 - val_loss: 9.9929\n",
      "Epoch 737/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 4.1330 - val_loss: 9.8542\n",
      "Epoch 738/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 4.1045 - val_loss: 9.8067\n",
      "Epoch 739/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 4.4498 - val_loss: 12.1436\n",
      "Epoch 740/800\n",
      "404/404 [==============================] - 0s 104us/step - loss: 6.4460 - val_loss: 10.5141\n",
      "Epoch 741/800\n",
      "404/404 [==============================] - 0s 104us/step - loss: 5.0898 - val_loss: 10.4989\n",
      "Epoch 742/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 4.2930 - val_loss: 10.1358\n",
      "Epoch 743/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 4.3260 - val_loss: 10.5540\n",
      "Epoch 744/800\n",
      "404/404 [==============================] - 0s 94us/step - loss: 4.6102 - val_loss: 10.0185\n",
      "Epoch 745/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 4.4871 - val_loss: 9.5856\n",
      "Epoch 746/800\n",
      "404/404 [==============================] - 0s 99us/step - loss: 4.1296 - val_loss: 10.2119\n",
      "Epoch 747/800\n",
      "404/404 [==============================] - 0s 99us/step - loss: 4.3119 - val_loss: 10.7261\n",
      "Epoch 748/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 4.7395 - val_loss: 9.6979\n",
      "Epoch 749/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 4.4354 - val_loss: 10.5906\n",
      "Epoch 750/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 4.6775 - val_loss: 10.3109\n",
      "Epoch 751/800\n",
      "404/404 [==============================] - 0s 95us/step - loss: 4.2171 - val_loss: 9.9631\n",
      "Epoch 752/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 6.2682 - val_loss: 12.9274\n",
      "Epoch 753/800\n",
      "404/404 [==============================] - 0s 111us/step - loss: 6.7037 - val_loss: 9.9186\n",
      "Epoch 754/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 4.3656 - val_loss: 9.9863\n",
      "Epoch 755/800\n",
      "404/404 [==============================] - 0s 118us/step - loss: 4.4266 - val_loss: 10.5724\n",
      "Epoch 756/800\n",
      "404/404 [==============================] - 0s 108us/step - loss: 4.4131 - val_loss: 10.6721\n",
      "Epoch 757/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 4.2526 - val_loss: 10.0257\n",
      "Epoch 758/800\n",
      "404/404 [==============================] - 0s 107us/step - loss: 4.3703 - val_loss: 10.5042\n",
      "Epoch 759/800\n",
      "404/404 [==============================] - 0s 89us/step - loss: 4.6534 - val_loss: 9.7416\n",
      "Epoch 760/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 4.5170 - val_loss: 10.1186\n",
      "Epoch 761/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 4.3513 - val_loss: 10.0527\n",
      "Epoch 762/800\n",
      "404/404 [==============================] - 0s 93us/step - loss: 4.1077 - val_loss: 10.0756\n",
      "Epoch 763/800\n",
      "404/404 [==============================] - 0s 126us/step - loss: 4.6721 - val_loss: 9.6726\n",
      "Epoch 764/800\n",
      "404/404 [==============================] - 0s 106us/step - loss: 5.0237 - val_loss: 10.2451\n",
      "Epoch 765/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 4.3669 - val_loss: 10.7069\n",
      "Epoch 766/800\n",
      "404/404 [==============================] - 0s 104us/step - loss: 4.3225 - val_loss: 10.2250\n",
      "Epoch 767/800\n",
      "404/404 [==============================] - 0s 98us/step - loss: 4.0945 - val_loss: 10.5240\n",
      "Epoch 768/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 4.9529 - val_loss: 11.0222\n",
      "Epoch 769/800\n",
      "404/404 [==============================] - 0s 99us/step - loss: 4.1103 - val_loss: 10.6403\n",
      "Epoch 770/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 4.4622 - val_loss: 11.1387\n",
      "Epoch 771/800\n",
      "404/404 [==============================] - 0s 109us/step - loss: 4.3390 - val_loss: 10.7923\n",
      "Epoch 772/800\n",
      "404/404 [==============================] - 0s 109us/step - loss: 5.4006 - val_loss: 10.2085\n",
      "Epoch 773/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 4.2492 - val_loss: 10.4119\n",
      "Epoch 774/800\n",
      "404/404 [==============================] - 0s 100us/step - loss: 5.6472 - val_loss: 11.3907\n",
      "Epoch 775/800\n",
      "404/404 [==============================] - 0s 110us/step - loss: 4.9442 - val_loss: 10.8744\n",
      "Epoch 776/800\n",
      "404/404 [==============================] - 0s 120us/step - loss: 5.6706 - val_loss: 9.8429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 777/800\n",
      "404/404 [==============================] - 0s 97us/step - loss: 4.3443 - val_loss: 9.7868\n",
      "Epoch 778/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 4.2528 - val_loss: 9.7019\n",
      "Epoch 779/800\n",
      "404/404 [==============================] - 0s 105us/step - loss: 4.5250 - val_loss: 9.9446\n",
      "Epoch 780/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 4.1133 - val_loss: 9.6242\n",
      "Epoch 781/800\n",
      "404/404 [==============================] - 0s 87us/step - loss: 5.7572 - val_loss: 9.9446\n",
      "Epoch 782/800\n",
      "404/404 [==============================] - 0s 83us/step - loss: 5.2866 - val_loss: 10.4710\n",
      "Epoch 783/800\n",
      "404/404 [==============================] - 0s 108us/step - loss: 4.7092 - val_loss: 10.0972\n",
      "Epoch 784/800\n",
      "404/404 [==============================] - 0s 126us/step - loss: 5.2575 - val_loss: 14.3045\n",
      "Epoch 785/800\n",
      "404/404 [==============================] - 0s 84us/step - loss: 5.6998 - val_loss: 9.5200\n",
      "Epoch 786/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 4.1406 - val_loss: 9.8692\n",
      "Epoch 787/800\n",
      "404/404 [==============================] - 0s 102us/step - loss: 4.3222 - val_loss: 9.9044\n",
      "Epoch 788/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 4.4773 - val_loss: 9.8150\n",
      "Epoch 789/800\n",
      "404/404 [==============================] - 0s 96us/step - loss: 5.0436 - val_loss: 9.7706\n",
      "Epoch 790/800\n",
      "404/404 [==============================] - 0s 103us/step - loss: 4.1010 - val_loss: 10.0784\n",
      "Epoch 791/800\n",
      "404/404 [==============================] - 0s 88us/step - loss: 4.0778 - val_loss: 10.1309\n",
      "Epoch 792/800\n",
      "404/404 [==============================] - 0s 108us/step - loss: 4.5163 - val_loss: 10.2289\n",
      "Epoch 793/800\n",
      "404/404 [==============================] - 0s 110us/step - loss: 4.2452 - val_loss: 10.9059\n",
      "Epoch 794/800\n",
      "404/404 [==============================] - 0s 99us/step - loss: 4.0988 - val_loss: 10.0684\n",
      "Epoch 795/800\n",
      "404/404 [==============================] - 0s 85us/step - loss: 4.1531 - val_loss: 10.9051\n",
      "Epoch 796/800\n",
      "404/404 [==============================] - 0s 108us/step - loss: 4.2977 - val_loss: 10.0194\n",
      "Epoch 797/800\n",
      "404/404 [==============================] - 0s 90us/step - loss: 4.0193 - val_loss: 9.7526\n",
      "Epoch 798/800\n",
      "404/404 [==============================] - 0s 104us/step - loss: 4.1862 - val_loss: 10.3799\n",
      "Epoch 799/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 4.3044 - val_loss: 10.1840\n",
      "Epoch 800/800\n",
      "404/404 [==============================] - 0s 86us/step - loss: 4.3588 - val_loss: 9.8350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0592c89f28>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_five_layers(input_dim=X_train.shape[1])\n",
    "\n",
    "# Compile the model with mean squared error (for regression)\n",
    "model.compile(optimizer='SGD', loss='mean_squared_error')\n",
    "\n",
    "# Now fit the model on 500 epoches with a batch size of 64\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=800, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_five_layers(input_dim):\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add the first Dense layers of 100 units with the input dimension\n",
    "    model.add(Dense(10, input_dim=input_dim, activation='tanh'))\n",
    "\n",
    "    # Add four more layers of 100 units\n",
    "    model.add(Dense(100, activation='tanh'))\n",
    "    model.add(Dense(100, activation='tanh'))\n",
    "    model.add(Dense(100, activation='tanh'))\n",
    "    model.add(Dense(100, activation='tanh'))\n",
    "\n",
    "\n",
    "    # Add finally the output layer with one unit: the predicted result\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 102 samples\n",
      "Epoch 1/160\n",
      "404/404 [==============================] - 2s 5ms/step - loss: 239.9488 - val_loss: 74.7757\n",
      "Epoch 2/160\n",
      "404/404 [==============================] - 0s 102us/step - loss: 412.1441 - val_loss: 365.8586\n",
      "Epoch 3/160\n",
      "404/404 [==============================] - 0s 111us/step - loss: 286.9857 - val_loss: 169.0072\n",
      "Epoch 4/160\n",
      "404/404 [==============================] - 0s 114us/step - loss: 124.3243 - val_loss: 69.2349\n",
      "Epoch 5/160\n",
      "404/404 [==============================] - 0s 119us/step - loss: 130.6326 - val_loss: 92.3761\n",
      "Epoch 6/160\n",
      "404/404 [==============================] - 0s 192us/step - loss: 72.0234 - val_loss: 57.4825\n",
      "Epoch 7/160\n",
      "404/404 [==============================] - 0s 145us/step - loss: 61.4476 - val_loss: 58.4205\n",
      "Epoch 8/160\n",
      "404/404 [==============================] - 0s 109us/step - loss: 58.2060 - val_loss: 63.5012\n",
      "Epoch 9/160\n",
      "404/404 [==============================] - 0s 111us/step - loss: 55.9006 - val_loss: 49.4444\n",
      "Epoch 10/160\n",
      "404/404 [==============================] - 0s 129us/step - loss: 67.8605 - val_loss: 51.3378\n",
      "Epoch 11/160\n",
      "404/404 [==============================] - 0s 110us/step - loss: 51.5857 - val_loss: 58.6986\n",
      "Epoch 12/160\n",
      "404/404 [==============================] - 0s 123us/step - loss: 85.1889 - val_loss: 45.6358\n",
      "Epoch 13/160\n",
      "404/404 [==============================] - 0s 120us/step - loss: 49.7920 - val_loss: 80.0658\n",
      "Epoch 14/160\n",
      "404/404 [==============================] - 0s 141us/step - loss: 67.3288 - val_loss: 46.3938\n",
      "Epoch 15/160\n",
      "404/404 [==============================] - 0s 116us/step - loss: 57.4339 - val_loss: 40.8490\n",
      "Epoch 16/160\n",
      "404/404 [==============================] - 0s 126us/step - loss: 38.8726 - val_loss: 60.2969\n",
      "Epoch 17/160\n",
      "404/404 [==============================] - 0s 125us/step - loss: 51.2222 - val_loss: 30.9303\n",
      "Epoch 18/160\n",
      "404/404 [==============================] - 0s 99us/step - loss: 29.5953 - val_loss: 27.1722\n",
      "Epoch 19/160\n",
      "404/404 [==============================] - 0s 129us/step - loss: 39.0806 - val_loss: 28.7555\n",
      "Epoch 20/160\n",
      "404/404 [==============================] - 0s 95us/step - loss: 26.8825 - val_loss: 63.3293\n",
      "Epoch 21/160\n",
      "404/404 [==============================] - 0s 85us/step - loss: 51.9535 - val_loss: 29.3439\n",
      "Epoch 22/160\n",
      "404/404 [==============================] - 0s 90us/step - loss: 27.6896 - val_loss: 41.1029\n",
      "Epoch 23/160\n",
      "404/404 [==============================] - 0s 109us/step - loss: 27.6722 - val_loss: 28.4764\n",
      "Epoch 24/160\n",
      "404/404 [==============================] - 0s 114us/step - loss: 23.4326 - val_loss: 24.7385\n",
      "Epoch 25/160\n",
      "404/404 [==============================] - 0s 91us/step - loss: 32.8103 - val_loss: 26.8972\n",
      "Epoch 26/160\n",
      "404/404 [==============================] - 0s 109us/step - loss: 20.9783 - val_loss: 25.0197\n",
      "Epoch 27/160\n",
      "404/404 [==============================] - 0s 105us/step - loss: 47.4446 - val_loss: 46.9899\n",
      "Epoch 28/160\n",
      "404/404 [==============================] - 0s 96us/step - loss: 24.6834 - val_loss: 29.3927\n",
      "Epoch 29/160\n",
      "404/404 [==============================] - 0s 102us/step - loss: 20.5160 - val_loss: 38.0541\n",
      "Epoch 30/160\n",
      "404/404 [==============================] - 0s 94us/step - loss: 25.3861 - val_loss: 19.0633\n",
      "Epoch 31/160\n",
      "404/404 [==============================] - 0s 92us/step - loss: 16.0916 - val_loss: 24.8600\n",
      "Epoch 32/160\n",
      "404/404 [==============================] - 0s 81us/step - loss: 30.0756 - val_loss: 38.3471\n",
      "Epoch 33/160\n",
      "404/404 [==============================] - 0s 95us/step - loss: 21.8964 - val_loss: 21.1400\n",
      "Epoch 34/160\n",
      "404/404 [==============================] - 0s 100us/step - loss: 16.8560 - val_loss: 22.0923\n",
      "Epoch 35/160\n",
      "404/404 [==============================] - 0s 109us/step - loss: 16.7775 - val_loss: 33.8657\n",
      "Epoch 36/160\n",
      "404/404 [==============================] - 0s 89us/step - loss: 22.7003 - val_loss: 34.6270\n",
      "Epoch 37/160\n",
      "404/404 [==============================] - 0s 103us/step - loss: 21.5632 - val_loss: 19.1208\n",
      "Epoch 38/160\n",
      "404/404 [==============================] - 0s 107us/step - loss: 16.7300 - val_loss: 18.0860\n",
      "Epoch 39/160\n",
      "404/404 [==============================] - 0s 87us/step - loss: 13.1536 - val_loss: 16.1882\n",
      "Epoch 40/160\n",
      "404/404 [==============================] - 0s 100us/step - loss: 15.8010 - val_loss: 18.7815\n",
      "Epoch 41/160\n",
      "404/404 [==============================] - 0s 104us/step - loss: 23.1548 - val_loss: 34.7860\n",
      "Epoch 42/160\n",
      "404/404 [==============================] - 0s 97us/step - loss: 15.5457 - val_loss: 15.9457\n",
      "Epoch 43/160\n",
      "404/404 [==============================] - 0s 100us/step - loss: 14.2950 - val_loss: 20.0966\n",
      "Epoch 44/160\n",
      "404/404 [==============================] - 0s 94us/step - loss: 21.0671 - val_loss: 32.1318\n",
      "Epoch 45/160\n",
      "404/404 [==============================] - 0s 105us/step - loss: 31.6333 - val_loss: 17.9252\n",
      "Epoch 46/160\n",
      "404/404 [==============================] - 0s 100us/step - loss: 15.2266 - val_loss: 14.5220\n",
      "Epoch 47/160\n",
      "404/404 [==============================] - 0s 91us/step - loss: 12.2957 - val_loss: 15.0438\n",
      "Epoch 48/160\n",
      "404/404 [==============================] - 0s 108us/step - loss: 13.4349 - val_loss: 24.9134\n",
      "Epoch 49/160\n",
      "404/404 [==============================] - 0s 105us/step - loss: 26.2253 - val_loss: 21.9505\n",
      "Epoch 50/160\n",
      "404/404 [==============================] - 0s 109us/step - loss: 14.2031 - val_loss: 25.2896\n",
      "Epoch 51/160\n",
      "404/404 [==============================] - 0s 106us/step - loss: 17.4294 - val_loss: 25.6852\n",
      "Epoch 52/160\n",
      "404/404 [==============================] - 0s 100us/step - loss: 16.7678 - val_loss: 14.1656\n",
      "Epoch 53/160\n",
      "404/404 [==============================] - 0s 107us/step - loss: 11.4649 - val_loss: 17.6196\n",
      "Epoch 54/160\n",
      "404/404 [==============================] - 0s 113us/step - loss: 14.2947 - val_loss: 31.7867\n",
      "Epoch 55/160\n",
      "404/404 [==============================] - 0s 105us/step - loss: 27.6861 - val_loss: 22.4327\n",
      "Epoch 56/160\n",
      "404/404 [==============================] - 0s 104us/step - loss: 21.6832 - val_loss: 17.2778\n",
      "Epoch 57/160\n",
      "404/404 [==============================] - 0s 108us/step - loss: 11.8397 - val_loss: 24.3668\n",
      "Epoch 58/160\n",
      "404/404 [==============================] - 0s 112us/step - loss: 12.9037 - val_loss: 15.8024\n",
      "Epoch 59/160\n",
      "404/404 [==============================] - 0s 110us/step - loss: 15.5668 - val_loss: 25.5283\n",
      "Epoch 60/160\n",
      "404/404 [==============================] - 0s 105us/step - loss: 21.6122 - val_loss: 18.8430\n",
      "Epoch 61/160\n",
      "404/404 [==============================] - 0s 109us/step - loss: 14.9015 - val_loss: 13.7248\n",
      "Epoch 62/160\n",
      "404/404 [==============================] - 0s 87us/step - loss: 9.4727 - val_loss: 13.2978\n",
      "Epoch 63/160\n",
      "404/404 [==============================] - 0s 110us/step - loss: 9.2284 - val_loss: 13.3923\n",
      "Epoch 64/160\n",
      "404/404 [==============================] - 0s 114us/step - loss: 8.6942 - val_loss: 12.8569\n",
      "Epoch 65/160\n",
      "404/404 [==============================] - 0s 97us/step - loss: 14.8020 - val_loss: 16.6859\n",
      "Epoch 66/160\n",
      "404/404 [==============================] - 0s 98us/step - loss: 11.1715 - val_loss: 13.2071\n",
      "Epoch 67/160\n",
      "404/404 [==============================] - 0s 111us/step - loss: 9.7209 - val_loss: 15.5737\n",
      "Epoch 68/160\n",
      "404/404 [==============================] - 0s 99us/step - loss: 8.9998 - val_loss: 14.0670\n",
      "Epoch 69/160\n",
      "404/404 [==============================] - 0s 95us/step - loss: 9.7286 - val_loss: 18.5079\n",
      "Epoch 70/160\n",
      "404/404 [==============================] - 0s 94us/step - loss: 9.9083 - val_loss: 19.8416\n",
      "Epoch 71/160\n",
      "404/404 [==============================] - 0s 97us/step - loss: 13.7448 - val_loss: 15.4726\n",
      "Epoch 72/160\n",
      "404/404 [==============================] - 0s 100us/step - loss: 15.6046 - val_loss: 20.3643\n",
      "Epoch 73/160\n",
      "404/404 [==============================] - 0s 114us/step - loss: 12.5803 - val_loss: 19.5337\n",
      "Epoch 74/160\n",
      "404/404 [==============================] - 0s 100us/step - loss: 9.7828 - val_loss: 19.6528\n",
      "Epoch 75/160\n",
      "404/404 [==============================] - 0s 109us/step - loss: 13.4731 - val_loss: 14.3322\n",
      "Epoch 76/160\n",
      "404/404 [==============================] - 0s 112us/step - loss: 9.7910 - val_loss: 14.4197\n",
      "Epoch 77/160\n",
      "404/404 [==============================] - 0s 94us/step - loss: 9.5793 - val_loss: 14.1532\n",
      "Epoch 78/160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "404/404 [==============================] - 0s 106us/step - loss: 9.8345 - val_loss: 13.8093\n",
      "Epoch 79/160\n",
      "404/404 [==============================] - 0s 109us/step - loss: 8.7778 - val_loss: 15.0486\n",
      "Epoch 80/160\n",
      "404/404 [==============================] - 0s 100us/step - loss: 8.0396 - val_loss: 12.2274\n",
      "Epoch 81/160\n",
      "404/404 [==============================] - 0s 112us/step - loss: 8.4163 - val_loss: 13.1997\n",
      "Epoch 82/160\n",
      "404/404 [==============================] - 0s 97us/step - loss: 10.0199 - val_loss: 15.6698\n",
      "Epoch 83/160\n",
      "404/404 [==============================] - 0s 98us/step - loss: 11.0356 - val_loss: 14.3503\n",
      "Epoch 84/160\n",
      "404/404 [==============================] - 0s 103us/step - loss: 8.1367 - val_loss: 12.2225\n",
      "Epoch 85/160\n",
      "404/404 [==============================] - 0s 117us/step - loss: 7.7973 - val_loss: 14.2885\n",
      "Epoch 86/160\n",
      "404/404 [==============================] - 0s 95us/step - loss: 14.1129 - val_loss: 12.5295\n",
      "Epoch 87/160\n",
      "404/404 [==============================] - 0s 99us/step - loss: 9.1779 - val_loss: 12.3111\n",
      "Epoch 88/160\n",
      "404/404 [==============================] - 0s 104us/step - loss: 7.4489 - val_loss: 12.7348\n",
      "Epoch 89/160\n",
      "404/404 [==============================] - 0s 92us/step - loss: 7.1951 - val_loss: 12.5040\n",
      "Epoch 90/160\n",
      "404/404 [==============================] - 0s 96us/step - loss: 7.2356 - val_loss: 13.3523\n",
      "Epoch 91/160\n",
      "404/404 [==============================] - 0s 95us/step - loss: 9.6122 - val_loss: 17.6832\n",
      "Epoch 92/160\n",
      "404/404 [==============================] - 0s 95us/step - loss: 8.9967 - val_loss: 12.9808\n",
      "Epoch 93/160\n",
      "404/404 [==============================] - 0s 96us/step - loss: 9.3810 - val_loss: 22.0904\n",
      "Epoch 94/160\n",
      "404/404 [==============================] - 0s 90us/step - loss: 12.6521 - val_loss: 12.8381\n",
      "Epoch 95/160\n",
      "404/404 [==============================] - 0s 107us/step - loss: 7.6993 - val_loss: 12.3683\n",
      "Epoch 96/160\n",
      "404/404 [==============================] - 0s 98us/step - loss: 7.6351 - val_loss: 11.6832\n",
      "Epoch 97/160\n",
      "404/404 [==============================] - 0s 89us/step - loss: 8.2222 - val_loss: 19.0462\n",
      "Epoch 98/160\n",
      "404/404 [==============================] - 0s 88us/step - loss: 12.3218 - val_loss: 14.5126\n",
      "Epoch 99/160\n",
      "404/404 [==============================] - 0s 109us/step - loss: 8.6529 - val_loss: 13.6902\n",
      "Epoch 100/160\n",
      "404/404 [==============================] - 0s 98us/step - loss: 7.9711 - val_loss: 12.2849\n",
      "Epoch 101/160\n",
      "404/404 [==============================] - 0s 105us/step - loss: 6.8916 - val_loss: 12.1856\n",
      "Epoch 102/160\n",
      "404/404 [==============================] - 0s 105us/step - loss: 7.1679 - val_loss: 12.3726\n",
      "Epoch 103/160\n",
      "404/404 [==============================] - 0s 119us/step - loss: 8.0632 - val_loss: 12.1033\n",
      "Epoch 104/160\n",
      "404/404 [==============================] - 0s 101us/step - loss: 8.4204 - val_loss: 13.7168\n",
      "Epoch 105/160\n",
      "404/404 [==============================] - 0s 103us/step - loss: 6.8724 - val_loss: 11.7753\n",
      "Epoch 106/160\n",
      "404/404 [==============================] - 0s 100us/step - loss: 11.1710 - val_loss: 22.1347\n",
      "Epoch 107/160\n",
      "404/404 [==============================] - 0s 103us/step - loss: 9.0037 - val_loss: 12.6793\n",
      "Epoch 108/160\n",
      "404/404 [==============================] - 0s 101us/step - loss: 6.6129 - val_loss: 11.7371\n",
      "Epoch 109/160\n",
      "404/404 [==============================] - 0s 96us/step - loss: 7.4894 - val_loss: 19.9190\n",
      "Epoch 110/160\n",
      "404/404 [==============================] - 0s 98us/step - loss: 14.3867 - val_loss: 14.4903\n",
      "Epoch 111/160\n",
      "404/404 [==============================] - 0s 95us/step - loss: 7.9735 - val_loss: 11.9845\n",
      "Epoch 112/160\n",
      "404/404 [==============================] - 0s 97us/step - loss: 7.3385 - val_loss: 21.3608\n",
      "Epoch 113/160\n",
      "404/404 [==============================] - 0s 101us/step - loss: 14.2547 - val_loss: 12.3614\n",
      "Epoch 114/160\n",
      "404/404 [==============================] - 0s 105us/step - loss: 7.4661 - val_loss: 13.2610\n",
      "Epoch 115/160\n",
      "404/404 [==============================] - 0s 105us/step - loss: 7.6036 - val_loss: 14.1501\n",
      "Epoch 116/160\n",
      "404/404 [==============================] - 0s 105us/step - loss: 7.5597 - val_loss: 11.4691\n",
      "Epoch 117/160\n",
      "404/404 [==============================] - 0s 98us/step - loss: 6.4846 - val_loss: 11.8916\n",
      "Epoch 118/160\n",
      "404/404 [==============================] - 0s 97us/step - loss: 6.6524 - val_loss: 16.1588\n",
      "Epoch 119/160\n",
      "404/404 [==============================] - 0s 92us/step - loss: 14.6832 - val_loss: 15.4845\n",
      "Epoch 120/160\n",
      "404/404 [==============================] - 0s 97us/step - loss: 8.4636 - val_loss: 12.2315\n",
      "Epoch 121/160\n",
      "404/404 [==============================] - 0s 94us/step - loss: 7.7716 - val_loss: 11.8225\n",
      "Epoch 122/160\n",
      "404/404 [==============================] - 0s 90us/step - loss: 7.3059 - val_loss: 11.8287\n",
      "Epoch 123/160\n",
      "404/404 [==============================] - 0s 117us/step - loss: 8.6150 - val_loss: 18.3937\n",
      "Epoch 124/160\n",
      "404/404 [==============================] - 0s 76us/step - loss: 8.5842 - val_loss: 18.6040\n",
      "Epoch 125/160\n",
      "404/404 [==============================] - 0s 82us/step - loss: 11.3003 - val_loss: 15.0909\n",
      "Epoch 126/160\n",
      "404/404 [==============================] - 0s 99us/step - loss: 7.4161 - val_loss: 12.5642\n",
      "Epoch 127/160\n",
      "404/404 [==============================] - 0s 90us/step - loss: 6.5626 - val_loss: 11.4695\n",
      "Epoch 128/160\n",
      "404/404 [==============================] - 0s 94us/step - loss: 7.4569 - val_loss: 14.1909\n",
      "Epoch 129/160\n",
      "404/404 [==============================] - 0s 93us/step - loss: 7.2159 - val_loss: 12.2760\n",
      "Epoch 130/160\n",
      "404/404 [==============================] - 0s 93us/step - loss: 6.7314 - val_loss: 12.5399\n",
      "Epoch 131/160\n",
      "404/404 [==============================] - 0s 96us/step - loss: 6.2168 - val_loss: 11.7528\n",
      "Epoch 132/160\n",
      "404/404 [==============================] - 0s 103us/step - loss: 6.4171 - val_loss: 14.1836\n",
      "Epoch 133/160\n",
      "404/404 [==============================] - 0s 103us/step - loss: 9.6929 - val_loss: 12.6066\n",
      "Epoch 134/160\n",
      "404/404 [==============================] - 0s 96us/step - loss: 7.4023 - val_loss: 13.1067\n",
      "Epoch 135/160\n",
      "404/404 [==============================] - 0s 118us/step - loss: 6.0189 - val_loss: 11.6524\n",
      "Epoch 136/160\n",
      "404/404 [==============================] - 0s 94us/step - loss: 6.3948 - val_loss: 12.9163\n",
      "Epoch 137/160\n",
      "404/404 [==============================] - 0s 83us/step - loss: 8.3975 - val_loss: 18.9588\n",
      "Epoch 138/160\n",
      "404/404 [==============================] - 0s 101us/step - loss: 7.5813 - val_loss: 11.7237\n",
      "Epoch 139/160\n",
      "404/404 [==============================] - 0s 96us/step - loss: 7.0749 - val_loss: 12.9894\n",
      "Epoch 140/160\n",
      "404/404 [==============================] - 0s 95us/step - loss: 6.2600 - val_loss: 11.9595\n",
      "Epoch 141/160\n",
      "404/404 [==============================] - 0s 93us/step - loss: 7.8001 - val_loss: 12.6999\n",
      "Epoch 142/160\n",
      "404/404 [==============================] - 0s 99us/step - loss: 7.6112 - val_loss: 12.0955\n",
      "Epoch 143/160\n",
      "404/404 [==============================] - 0s 99us/step - loss: 6.6564 - val_loss: 12.4448\n",
      "Epoch 144/160\n",
      "404/404 [==============================] - 0s 105us/step - loss: 6.2156 - val_loss: 11.7735\n",
      "Epoch 145/160\n",
      "404/404 [==============================] - 0s 95us/step - loss: 6.6029 - val_loss: 12.2222\n",
      "Epoch 146/160\n",
      "404/404 [==============================] - 0s 118us/step - loss: 6.1022 - val_loss: 12.7738\n",
      "Epoch 147/160\n",
      "404/404 [==============================] - 0s 110us/step - loss: 6.5494 - val_loss: 13.2178\n",
      "Epoch 148/160\n",
      "404/404 [==============================] - 0s 112us/step - loss: 6.2577 - val_loss: 12.3775\n",
      "Epoch 149/160\n",
      "404/404 [==============================] - 0s 125us/step - loss: 6.0574 - val_loss: 13.8042\n",
      "Epoch 150/160\n",
      "404/404 [==============================] - 0s 134us/step - loss: 7.3697 - val_loss: 12.6168\n",
      "Epoch 151/160\n",
      "404/404 [==============================] - 0s 154us/step - loss: 6.4062 - val_loss: 12.0704\n",
      "Epoch 152/160\n",
      "404/404 [==============================] - 0s 107us/step - loss: 5.7831 - val_loss: 11.6628\n",
      "Epoch 153/160\n",
      "404/404 [==============================] - 0s 98us/step - loss: 5.8445 - val_loss: 15.0648\n",
      "Epoch 154/160\n",
      "404/404 [==============================] - 0s 90us/step - loss: 7.4789 - val_loss: 12.4397\n",
      "Epoch 155/160\n",
      "404/404 [==============================] - 0s 98us/step - loss: 6.2170 - val_loss: 11.8538\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/160\n",
      "404/404 [==============================] - 0s 105us/step - loss: 5.6577 - val_loss: 12.0551\n",
      "Epoch 157/160\n",
      "404/404 [==============================] - 0s 104us/step - loss: 5.7942 - val_loss: 16.2726\n",
      "Epoch 158/160\n",
      "404/404 [==============================] - 0s 95us/step - loss: 12.4922 - val_loss: 16.6726\n",
      "Epoch 159/160\n",
      "404/404 [==============================] - 0s 91us/step - loss: 8.2830 - val_loss: 12.1543\n",
      "Epoch 160/160\n",
      "404/404 [==============================] - 0s 98us/step - loss: 6.8963 - val_loss: 14.1619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0590b21dd8>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_five_layers(input_dim=X_train.shape[1])\n",
    "\n",
    "# Compile the model with mean squared error (for regression)\n",
    "model.compile(optimizer='SGD', loss='mean_squared_error')\n",
    "\n",
    "# Now fit the model on 500 epoches with a batch size of 64\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=160, batch_size=62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_70 (Dense)             (None, 10)                140       \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 591\n",
      "Trainable params: 591\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
